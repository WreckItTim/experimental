{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdd5d440",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8869ebfb-5987-42e3-a189-833c8bacdbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to edit navi_eval -- \n",
    "    # comment out os.chdir at top of navi_eval.py \n",
    "    # remove reinforcement_learning/ from path in reinforcement_learning.py\n",
    "\n",
    "## ** insert this head at top of all main files with your proper paths **\n",
    "local_dir = '/home/tim/local/' # any local files outside of repo\n",
    "home_dir = '/home/tim/Dropbox/experimental/' # home directory of repo\n",
    "import os\n",
    "#os.chdir(home_dir)\n",
    "import sys\n",
    "sys.path.append(home_dir)\n",
    "# optional imports of useful global methods\n",
    "import utils.global_methods as gm # common utility methods\n",
    "import map_data.map_methods as mm # data fetching and handling methods\n",
    "import reinforcement_learning.reinforcement_methods as rm # common overarching methods used for DRL\n",
    "\n",
    "\n",
    "## local imports\n",
    "from configuration import Configuration\n",
    "import math\n",
    "import random\n",
    "initial_locals = locals().copy() # will exclude these parameters from config parameters written to file\n",
    "\n",
    "\n",
    "## default parameters\n",
    "\n",
    "# misc\n",
    "random_seed = 42\n",
    "# job_name = f'null_{random.randint(0, 1_000_000)}'\n",
    "# output_dir = 'null'\n",
    "job_name = 'debug'\n",
    "output_dir = 'models/navi_debug/'\n",
    "continue_training = False\n",
    "contine_model_at = None # specify model path to continue training from\n",
    "contine_config_at = None # specify configuration path to continue training from\n",
    "contine_buffer_at = None\n",
    "overwrite_directory = False # True will erase all files at otuput working directory\n",
    "\n",
    "# environment\n",
    "airsim_map = 'AirSimNH'\n",
    "rooftops_version = 'v1'\n",
    "region = 'all'\n",
    "map_resolution_x, map_resolution_y, map_resolution_z = 2, 2, 4\n",
    "\n",
    "# observation space\n",
    "sensor_name = 'DepthV2' # forward sensor to use as input to navigation model\n",
    "nPast = 4\n",
    "id_name = 'alpha' # when reading in observation data, which ID key words to use\n",
    "\n",
    "# action space\n",
    "motion = '2d'\n",
    "actions = [\n",
    "    'RotateRight90',\n",
    "    'RotateLeft90',\n",
    "    'MoveForward2',\n",
    "    'MoveForward4',\n",
    "    #'MoveForward6',\n",
    "    'MoveForward8',\n",
    "    #'MoveForward10',\n",
    "    'MoveForward16',\n",
    "    'MoveForward32',\n",
    "    #'PivotRight2',\n",
    "    #'PivotLeft2',\n",
    "]\n",
    "if motion == '3d':\n",
    "    actions = actions + [\n",
    "        'MoveDownward4',\n",
    "        'MoveUpward4',\n",
    "    ]\n",
    "\n",
    "# reward function\n",
    "goal_tolerance = 4\n",
    "astar_multiplier = 2 # determines max length of an episode\n",
    "\n",
    "# levels spawner\n",
    "astar_name = 'all' # 46812 paths\n",
    "astar_version = 'v1' \n",
    "level_proba = 1.0\n",
    "split_name = 'train'\n",
    "split_train_start = 0\n",
    "split_train_end = 0.6\n",
    "split_val_start = 0.6\n",
    "split_val_end = 0.8\n",
    "split_test_start = 0.8\n",
    "split_test_end = 1\n",
    "\n",
    "# curriculum learning\n",
    "min_level, max_level = 0, 7 # index range of path difficulties to train and evaluate on, inclusive\n",
    "#early_freq = 10_000\n",
    "#early_criteria = 0.8\n",
    "early_freq = 1_000\n",
    "early_criteria = 0.6\n",
    "eval_train_freq = 40_000\n",
    "eval_test_freq = 40_000\n",
    "eval_train_use_current_as_min_level = False\n",
    "eval_val_use_current_as_min_level = True\n",
    "eval_test_use_current_as_min_level = False\n",
    "eval_train_use_current_as_max_level = False\n",
    "eval_val_use_current_as_max_level = True\n",
    "eval_test_use_current_as_max_level = False\n",
    "\n",
    "# DQN policy\n",
    "net_arch_nodes = 64\n",
    "net_arch_layers = 2\n",
    "feature_extractor_scale = 1\n",
    "feature_extractor_dim = 256\n",
    "total_policy_scale = 1\n",
    "device = 'cuda:0'\n",
    "\n",
    "# learning algorithm\n",
    "total_timesteps = int(1e7) # maximum number of timesteps to train on\n",
    "    # SB3 default is 1e6, Microsoft uses 5e5\n",
    "buffer_size = int(1e5) # number of recent steps (observation, action, reward) tuples to store in memory to train on -- takes up memory\n",
    "    # ^^ SB3 default is 1e6, Microsoft uses 5e5, I typically have to use less because of memory constraints\n",
    "#exploration_fraction =  0.1\n",
    "stop_annealing = int(4e4) # number of steps to stop annealing the exploration rate at\n",
    "    \n",
    "\n",
    "# read params from command line\n",
    "# if len(sys.argv) > 1:\n",
    "#     arguments = gm.parse_arguments(sys.argv[1:])\n",
    "#     locals().update(arguments)\n",
    "# assert output_dir!='null', f'output_dir not passed as arg'\n",
    "gm.set_global('job_name', job_name)\n",
    "gm.set_global('home_dir', home_dir)\n",
    "gm.set_global('local_dir', local_dir)\n",
    "gm.set_global('device', device)\n",
    "gm.set_random_seed(random_seed)\n",
    "\n",
    "# set variable subpaths from root directories and params set above\n",
    "astar_dir = f'{home_dir}map_data/astar_paths/'\n",
    "rooftops_dir = f'{home_dir}map_data/rooftops/'\n",
    "observations_dir = f'{home_dir}map_data/observations/'\n",
    "astar_paths_file = f'{astar_dir}{astar_version}/{airsim_map}_{motion}_{astar_name}.p'\n",
    "rooftops_path = f'{rooftops_dir}{rooftops_version}/{airsim_map}.p' # match to map or use voxels if not available\n",
    "sensor_info = gm.read_json(f'{observations_dir}{sensor_name}/info.json')\n",
    "image_bands, image_height, image_width = sensor_info['array_size']\n",
    "complete_path = f'{output_dir}completed.p' # path to check if this job is done already\n",
    "gm.set_global('complete_path', complete_path)\n",
    "\n",
    "# how to handle if completed path already exists (showing a previous job has finished this data collection already)\n",
    "if os.path.exists(complete_path):\n",
    "    if overwrite_directory:\n",
    "        os.remove(complete_path)\n",
    "    else:\n",
    "        gm.progress(job_name, 'complete')\n",
    "        sys.exit()\n",
    "\n",
    "# setup output directory\n",
    "gm.setup_output_dir(output_dir, overwrite_directory)\n",
    "\n",
    "# bounds drone can move in\n",
    "x_bounds, y_bounds, z_bounds = mm.get_bounds(airsim_map, region, motion)\n",
    "x_vals = [x for x in range(x_bounds[0], x_bounds[1]+1, map_resolution_x)]\n",
    "y_vals = [y for y in range(y_bounds[0], y_bounds[1]+1, map_resolution_y)]\n",
    "z_vals = [z for z in range(z_bounds[0], z_bounds[1]+1, map_resolution_z)]\n",
    "yaw_vals = [0, 1, 2, 3] # what yaws are accessible by drone\n",
    "\n",
    "# how astar paths are split into sets and evaluated\n",
    "eval_val_freq = early_freq\n",
    "path_splits = {\n",
    "    'train':[split_train_start, split_train_end],\n",
    "    'val':[split_val_start, split_val_end],\n",
    "    'test':[split_test_start, split_test_end],\n",
    "}\n",
    "eval_frequencies = {}\n",
    "eval_use_current_as_min_level = {}\n",
    "eval_use_current_as_max_level = {}\n",
    "if eval_train_freq > 0:\n",
    "    eval_frequencies['train'] = eval_train_freq\n",
    "    eval_use_current_as_min_level['train'] = eval_train_use_current_as_min_level\n",
    "    eval_use_current_as_max_level['train'] = eval_train_use_current_as_max_level\n",
    "if eval_val_freq > 0:\n",
    "    eval_frequencies['val'] = eval_val_freq\n",
    "    eval_use_current_as_min_level['val'] = eval_val_use_current_as_min_level\n",
    "    eval_use_current_as_max_level['val'] = eval_val_use_current_as_max_level\n",
    "if eval_test_freq > 0:\n",
    "    eval_frequencies['test'] = eval_test_freq\n",
    "    eval_use_current_as_min_level['test'] = eval_test_use_current_as_min_level\n",
    "    eval_use_current_as_max_level['test'] = eval_test_use_current_as_max_level\n",
    "\n",
    "# misc\n",
    "exploration_fraction = stop_annealing / total_timesteps\n",
    "    # SB3 default is 0.1*total_timesteps, Microsoft uses 5e4\n",
    "\n",
    "# all variables here will be added to configuration parameters for reading later\n",
    "all_local_vars = locals()\n",
    "user_local_vars = {k:v for k, v in all_local_vars.items() if (not k.startswith('__') and k not in initial_locals and k not in ['initial_locals','all_local_vars'])}\n",
    "config_params = user_local_vars.copy() # will include all of the above parameters to config parameters written to file\n",
    "\n",
    "\n",
    "# COMPONENTS\n",
    "\n",
    "# make controller to run configuration on (we will train a model)\n",
    "from controllers.train import Train\n",
    "controller = Train(\n",
    "    model_component = 'Model',\n",
    "    environment_component = 'Environment',\n",
    "    continue_training = continue_training,\n",
    "    total_timesteps = total_timesteps,\n",
    "    )\n",
    "\n",
    "# continue training will load runs folder and pick up where it left off\n",
    "if continue_training:\n",
    "    # load configuration file and create object to save and connect components\n",
    "    if contine_config_at is None:\n",
    "        contine_config_at = output_dir + 'configuration.json'\n",
    "    configuration = Configuration.load(contine_config_at, controller)\n",
    "    meta = configuration.meta\n",
    "    meta['continued_training'] = True\n",
    "    # read model and/or replay buffer\n",
    "    # get highest level complete\n",
    "    modeling_dir = f'{output_dir}modeling/'\n",
    "    if contine_buffer_at is None:\n",
    "        contine_buffer_at = f'{modeling_dir}replay_buffer.zip'\n",
    "    if contine_model_at is None:\n",
    "        final_model_path = f'{modeling_dir}model_final.zip'\n",
    "        if os.path.exists(final_model_path):\n",
    "            contine_model_at = final_model_path\n",
    "        else:\n",
    "            highest_level = -1\n",
    "            fnames = os.listdir(modeling_dir)\n",
    "            for fname in fnames:\n",
    "                if 'model' in fname:\n",
    "                    parts = fname.split('.')[0].split('_')\n",
    "                    level = int(parts[2])\n",
    "                    if level > highest_level:\n",
    "                        highest_level = level\n",
    "                        contine_model_at = f'{modeling_dir}{fname}'\n",
    "    model_component = configuration.get_component('Model')\n",
    "    model_component.read_model_path = contine_model_at\n",
    "    model_component.read_replay_buffer_path = contine_buffer_at\n",
    "    gm.speak('continuing training...')\n",
    "\n",
    "# if not continuing training then make a brand spaking new config\n",
    "else:\n",
    "    # set meta data (anything you want here, just writes to config file as a dict)\n",
    "    meta = {\n",
    "        }\n",
    "\n",
    "    ## make a new configuration file to add components to \n",
    "        # this obj will be used to serialize components, and log experiment history\n",
    "        # any components created after making this configuration file will auto be added to it\n",
    "        # components use the name of other components which will be created and connected later\n",
    "        # this is done to handle different objects which need to be connected to eachother and connected in different orders\n",
    "        # there is a baked in priority que for connecting components if you need to handle this differently\n",
    "    configuration = Configuration(meta)\n",
    "    configuration.set_controller(controller)\n",
    "    for key in config_params:\n",
    "        configuration.set_parameter(key, config_params[key])\n",
    "\n",
    "    ## create environment component to handle step() and reset() for DRL model training\n",
    "    from environments.goalenv import GoalEnv\n",
    "    GoalEnv(\n",
    "        drone_component = 'Drone', \n",
    "        actor_component = 'Actor', \n",
    "        observer_component = 'Observer', \n",
    "        rewarder_component = 'Rewarder',\n",
    "        model_component = 'Model',\n",
    "        map_component = 'Map',\n",
    "        spawner_component = 'Spawner',\n",
    "        crash_handler = False,\n",
    "        name = 'Environment',\n",
    "        )\n",
    "\n",
    "    # create map object\n",
    "    from maps.etherial import Etherial\n",
    "    Etherial(\n",
    "        rooftops_component='Rooftops',\n",
    "        x_bounds = x_bounds,\n",
    "        y_bounds = y_bounds,\n",
    "        z_bounds = z_bounds,\n",
    "        name = 'Map',\n",
    "        )\n",
    "    # read rooftops data struct to determine z-height of nearest collidable object below or above x,y coords\n",
    "    from others.rooftops import Rooftops\n",
    "    Rooftops(\n",
    "        read_path = rooftops_path,\n",
    "        name = 'Rooftops',\n",
    "    )\n",
    "\n",
    "    # drone controller component - we will use AirSim\n",
    "        # this can also be real world drone controller like Tello\n",
    "    from drones.etherial import Etherial\n",
    "    Etherial(\n",
    "        map_component = 'Map',\n",
    "        name = 'Drone',\n",
    "        )\n",
    "\n",
    "    ## REWARD FUNCTION\n",
    "    # we will reward moving closer, reward reaching goal, penalize too many steps, and penalize collisions\n",
    "    rewards = []\n",
    "    reward_weights = []\n",
    "    # heavy penalty for out of bounds\n",
    "    from rewards.bounds import Bounds\n",
    "    Bounds(\n",
    "        drone_component = 'Drone',\n",
    "        x_bounds = x_bounds,\n",
    "        y_bounds = y_bounds,\n",
    "        z_bounds = z_bounds,\n",
    "        name = 'BoundsReward',\n",
    "        )\n",
    "    rewards.append('BoundsReward')\n",
    "    reward_weights.append(1)\n",
    "    # heavy penalty for collision\n",
    "    from rewards.collision import Collision\n",
    "    Collision(\n",
    "        drone_component = 'Drone',\n",
    "        name = 'CollisionReward',\n",
    "        )\n",
    "    rewards.append('CollisionReward')\n",
    "    reward_weights.append(1)\n",
    "    # heavy reward for reaching goal\n",
    "    from rewards.goal import Goal\n",
    "    Goal(\n",
    "        drone_component = 'Drone',\n",
    "        goal_component = 'Spawner',\n",
    "        include_z = True if motion in '3d' else False, # includes z in distance calculations\n",
    "        tolerance = goal_tolerance, # must reach goal within this many meters\n",
    "        terminate = True, # we are terminating this example when the drone realizes it reached the goal, collides, or reaches max\n",
    "        name = 'GoalReward',\n",
    "        )\n",
    "    rewards.append('GoalReward')\n",
    "    reward_weights.append(10)\n",
    "    # heavy penalty for using too many steps\n",
    "    from rewards.maxsteps import MaxSteps\n",
    "    MaxSteps(\n",
    "        spawner_component = 'Spawner',\n",
    "        max_max = 50, # absolute max number of steps, regardless of scaling from further goals\n",
    "        use_astar = True, # bases max steps based on astar length\n",
    "        astar_multiplier = astar_multiplier, # max step size is this many times the astar length\n",
    "        name = 'MaxStepsReward',\n",
    "        )\n",
    "    rewards.append('MaxStepsReward')\n",
    "    reward_weights.append(1)\n",
    "    # intermediate penalty for using more steps\n",
    "    from rewards.steps import Steps\n",
    "    Steps(\n",
    "        name = 'StepsReward',\n",
    "        )\n",
    "    rewards.append('StepsReward')\n",
    "    reward_weights.append(.1)\n",
    "    # intermediate reward for approaching goal\n",
    "    from rewards.distance import Distance\n",
    "    Distance(\n",
    "        drone_component = 'Drone',\n",
    "        goal_component = 'Spawner',\n",
    "        include_z = True if motion in '3d' else False, # includes z in distance calculations\n",
    "        name = 'DistanceReward',\n",
    "        )\n",
    "    rewards.append('DistanceReward')\n",
    "    reward_weights.append(.1)\n",
    "    # REWARDER\n",
    "    from rewarders.schema import Schema\n",
    "    Schema(\n",
    "        rewards_components = rewards,\n",
    "        reward_weights = reward_weights, \n",
    "        name = 'Rewarder',\n",
    "        )\n",
    "\n",
    "    ## ACTION SPACE\n",
    "    # we will just move forward and rotate for this example\n",
    "    from actions.fixedrotate import FixedRotate \n",
    "    FixedRotate(\n",
    "        drone_component = 'Drone',  \n",
    "        yaw_diff = math.pi/2, # can rotate at 90 deg increments\n",
    "        name = 'RotateRight90',\n",
    "        )\n",
    "    FixedRotate(\n",
    "        drone_component = 'Drone',  \n",
    "        yaw_diff = -1*math.pi/2, # can rotate at 90 deg increments\n",
    "        name = 'RotateLeft90',\n",
    "        )\n",
    "    from actions.fixedmove import FixedMove\n",
    "    FixedMove(\n",
    "        drone_component = 'Drone', \n",
    "        x_distance = 2,\n",
    "        adjust_for_yaw = True, # this adjusts movement based on current yaw for relative moves\n",
    "        name = 'MoveForward2',\n",
    "        )\n",
    "    FixedMove(\n",
    "        drone_component = 'Drone', \n",
    "        x_distance = 4,\n",
    "        adjust_for_yaw = True, # this adjusts movement based on current yaw for relative moves\n",
    "        name = 'MoveForward4',\n",
    "        )\n",
    "    FixedMove(\n",
    "        drone_component = 'Drone', \n",
    "        x_distance = 6,\n",
    "        adjust_for_yaw = True, # this adjusts movement based on current yaw for relative moves\n",
    "        name = 'MoveForward6',\n",
    "        )\n",
    "    FixedMove(\n",
    "        drone_component = 'Drone', \n",
    "        x_distance = 8,\n",
    "        adjust_for_yaw = True, # this adjusts movement based on current yaw for relative moves\n",
    "        name = 'MoveForward8',\n",
    "        )\n",
    "    FixedMove(\n",
    "        drone_component = 'Drone', \n",
    "        x_distance = 10,\n",
    "        adjust_for_yaw = True, # this adjusts movement based on current yaw for relative moves\n",
    "        name = 'MoveForward10',\n",
    "        )\n",
    "    FixedMove(\n",
    "        drone_component = 'Drone', \n",
    "        x_distance = 16,\n",
    "        adjust_for_yaw = True, # this adjusts movement based on current yaw for relative moves\n",
    "        name = 'MoveForward16',\n",
    "        )\n",
    "    FixedMove(\n",
    "        drone_component = 'Drone', \n",
    "        x_distance = 32,\n",
    "        adjust_for_yaw = True, # this adjusts movement based on current yaw for relative moves\n",
    "        name = 'MoveForward32',\n",
    "        )\n",
    "    FixedMove(\n",
    "        drone_component = 'Drone', \n",
    "        y_distance = 2,\n",
    "        adjust_for_yaw = True, # this adjusts movement based on current yaw for relative moves\n",
    "        name = 'PivotRight2',\n",
    "        )\n",
    "    FixedMove(\n",
    "        drone_component = 'Drone', \n",
    "        y_distance = -2,\n",
    "        adjust_for_yaw = True, # this adjusts movement based on current yaw for relative moves\n",
    "        name = 'PivotLeft2',\n",
    "        )\n",
    "    FixedMove(\n",
    "        drone_component = 'Drone', \n",
    "        z_distance = 4,\n",
    "        name = 'MoveDownward4',\n",
    "        )\n",
    "    FixedMove(\n",
    "        drone_component = 'Drone', \n",
    "        z_distance = -4,\n",
    "        name = 'MoveUpward4',\n",
    "        )\n",
    "\n",
    "    ## ACTOR\n",
    "    from actors.teleporterdiscrete import TeleporterDiscrete\n",
    "    # we use a teleporter here because it is quicker and more stable\n",
    "        # it will check collisions between current point and telported point then move directly to that location\n",
    "    TeleporterDiscrete(\n",
    "        drone_component = 'Drone',\n",
    "        actions_components = actions,\n",
    "        discretize=True,\n",
    "        name = 'Actor',\n",
    "        )\n",
    "\n",
    "    ## OBSERVATION SPACE\n",
    "    # we will use the relative displacement between drone and goal, and front-facing depth maps\n",
    "    # we will use the T0many most recent observations concatenated toghter, for this example T = 4\n",
    "    # TRANSFORMERS\n",
    "    from transformers.normalize import Normalize\n",
    "    Normalize(\n",
    "        min_input = -1*math.pi, # min angle\n",
    "        max_input = math.pi, # max angle\n",
    "        name = 'NormalizeOrientation',\n",
    "        )\n",
    "    Normalize(\n",
    "        min_input = 1, # in front of sensor\n",
    "        max_input = 100, # horizon\n",
    "        left = 0,\n",
    "        name = 'NormalizeDistance',\n",
    "        )\n",
    "    \n",
    "    # SENSORS\n",
    "    vector_sensors = []\n",
    "    vector_length_forget = 0\n",
    "    vector_length_remember = 0\n",
    "    img_sensors = []\n",
    "    image_bands_forget = 0\n",
    "    image_bands_remember = 0\n",
    "    # forward depth sensor\n",
    "    from others.datadict import DataDict\n",
    "    DataDict(\n",
    "        data_dir = f'{observations_dir}{sensor_name}/{airsim_map}/',\n",
    "        id_name=id_name, x_vals=x_vals, y_vals=y_vals, z_vals=z_vals, yaw_vals=yaw_vals,\n",
    "        name = 'DataDictForward',\n",
    "    )\n",
    "    from sensors.cache import Cache\n",
    "    Cache(\n",
    "        datadict_component = 'DataDictForward',\n",
    "        drone_component = 'Drone',\n",
    "        sensor_name = sensor_name,\n",
    "        sensor_dir = f'{observations_dir}{sensor_name}/',\n",
    "        map_name = airsim_map,\n",
    "        transformers_components=[],\n",
    "        name = sensor_name,\n",
    "    )\n",
    "    img_sensors.append(sensor_name)\n",
    "    image_bands_remember += image_bands\n",
    "    # sense horz distance to goal\n",
    "    from sensors.distance import Distance\n",
    "    Distance(\n",
    "        misc_component = 'Drone',\n",
    "        misc2_component = 'Spawner',\n",
    "        include_x = True,\n",
    "        include_y = True,\n",
    "        include_z = False,\n",
    "        prefix = 'drone_to_goal',\n",
    "        transformers_components = [\n",
    "            'NormalizeDistance',\n",
    "            ], \n",
    "        name = 'GoalDistanceXY',\n",
    "        )\n",
    "    vector_sensors.append('GoalDistanceXY')\n",
    "    vector_length_remember += 1\n",
    "    # sense yaw difference to goal \n",
    "    from sensors.orientation import Orientation\n",
    "    Orientation(\n",
    "        misc_component = 'Drone',\n",
    "        misc2_component = 'Spawner',\n",
    "        prefix = 'drone_to_goal',\n",
    "        transformers_components = [\n",
    "            'NormalizeOrientation',\n",
    "            ],\n",
    "        name = 'GoalOrientation',\n",
    "        )\n",
    "    vector_sensors.append('GoalOrientation')\n",
    "    vector_length_remember += 1\n",
    "    from sensors.distancebounds import DistanceBounds\n",
    "    DistanceBounds(\n",
    "        drone_component = 'Drone',\n",
    "        x_bounds = x_bounds,\n",
    "        y_bounds = y_bounds,\n",
    "        z_bounds = z_bounds,\n",
    "        include_z = True if motion in '3d' else False,\n",
    "        transformers_components = [\n",
    "            'NormalizeDistance',\n",
    "            ],\n",
    "        name = 'DistanceBounds',\n",
    "    )\n",
    "    vector_sensors.append('DistanceBounds')\n",
    "    vector_length_remember += 1\n",
    "    # sense vert distance to goal\n",
    "    if motion in '3d':\n",
    "        Distance(\n",
    "            misc_component = 'Drone',\n",
    "            misc2_component = 'Spawner',\n",
    "            include_x = False,\n",
    "            include_y = False,\n",
    "            include_z = True,\n",
    "            prefix = 'drone_to_goal',\n",
    "            transformers_components = [\n",
    "                'NormalizeDistance',\n",
    "                ], \n",
    "            name = 'GoalDistanceZ',\n",
    "            )\n",
    "        vector_sensors.append('GoalDistanceZ')\n",
    "        vector_length_remember += 1\n",
    "    # OBSERVER\n",
    "    # currently must count vector size of sensor output\n",
    "    from observers.single import Single\n",
    "    Single(\n",
    "        map_component = 'Map',\n",
    "        sensors_components = vector_sensors,\n",
    "        vector_length_forget = vector_length_forget,\n",
    "        vector_length_remember = vector_length_remember,\n",
    "        nPast = nPast,\n",
    "        null_if_in_obj = True, # inside an object\n",
    "        null_if_oob = True, # out of bounds\n",
    "        name = 'VecObserver',\n",
    "        )\n",
    "    Single(\n",
    "        sensors_components = img_sensors, \n",
    "        is_image = True,\n",
    "        image_height = image_height, \n",
    "        image_width = image_width,\n",
    "        image_bands_forget = image_bands_forget,\n",
    "        image_bands_remember = image_bands_remember,\n",
    "        nPast = nPast,\n",
    "        null_if_in_obj = True, # inside an object\n",
    "        null_if_oob = True, # out of bounds\n",
    "        name = 'ImgObserver',\n",
    "        )\n",
    "    from observers.multi import Multi\n",
    "    Multi(\n",
    "        vector_observer_component = 'VecObserver',\n",
    "        image_observer_component = 'ImgObserver',\n",
    "        name = 'Observer',\n",
    "        )\n",
    "\n",
    "\n",
    "    ## MODEL\n",
    "        # we will use a TD3 algorithm from SB3\n",
    "    from sb3models.dqn import DQN\n",
    "    DQN(\n",
    "        environment_component = 'Environment',\n",
    "        policy = 'MultiInputPolicy',\n",
    "        buffer_size = buffer_size,\n",
    "        device = device,\n",
    "        exploration_fraction = exploration_fraction,\n",
    "        # calling custom methods for 3rd party libraries is messy\n",
    "        # note that the _class features are strings to make them json configuration compatidble\n",
    "        # I wrote a str_to_class() method in sb3model to adjust for this by converting to class at run time\n",
    "        policy_kwargs = {\n",
    "            'net_arch':[int(total_policy_scale*net_arch_nodes) for _ in range(net_arch_layers)],\n",
    "            'features_extractor_class':'CombinedExtractor_tim', # CombinedExtractor_tim\n",
    "            'features_extractor_kwargs':{\n",
    "                'cnn_output_dim':int(total_policy_scale*feature_extractor_dim),\n",
    "                'normalized_image':False,\n",
    "                'tim_cnn_class':'NatureCNN_tim', # NatureCNN_tim\n",
    "                'tim_cnn_kwargs':{\n",
    "                    'scale':total_policy_scale*feature_extractor_scale,\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "        name = 'Model',\n",
    "    )\n",
    "\n",
    "    # SPAWNER\n",
    "        # moves drone to desired starting location\n",
    "        # sets the target goal since it is typically dependent on the start location\n",
    "    from spawners.levels import Levels\n",
    "    Levels(\n",
    "        drone_component = 'Drone',\n",
    "        levels_path = astar_paths_file,\n",
    "        min_level = min_level,\n",
    "        max_level = max_level,\n",
    "        random_path = True,\n",
    "        path_splits = path_splits,\n",
    "        split_name = 'train',\n",
    "        level_proba = level_proba,\n",
    "        name = 'Spawner',\n",
    "    )\n",
    "\n",
    "    ## MODIFIERS\n",
    "        # modifiers are like wrappers, and will add functionality before or after any component\n",
    "    # CURRICULUM LEARNING\n",
    "        # this modifier will be called at the end of every episode to see the percent of succesfull paths\n",
    "        # if enough paths were succesfull then this will level up to harder goal\n",
    "    from modifiers.curriculum import Curriculum\n",
    "    Curriculum(\n",
    "        base_component = 'Environment',\n",
    "        parent_method = 'end',\n",
    "        order = 'post',\n",
    "        spawner_component = 'Spawner', # which component to level up\n",
    "        model_component = 'Model',\n",
    "        min_level = min_level, # will start at this level unless specified with level argument\n",
    "        max_level = max_level, # can level up this many times after will terminate DRL learning loop\n",
    "        update_progress = True,\n",
    "        eval_frequencies = eval_frequencies,\n",
    "        eval_use_current_as_min_level = eval_use_current_as_min_level,\n",
    "        eval_use_current_as_max_level = eval_use_current_as_max_level,\n",
    "        use_early = True,\n",
    "        patience = 10,\n",
    "        early_freq = early_freq,\n",
    "        early_criteria = early_criteria,\n",
    "        name = 'Curriculum',\n",
    "    )\n",
    "    # SAVERS\n",
    "        # these will save any intermediate data we want during the training process\n",
    "    from modifiers.saver import Saver\n",
    "    checkpoint_freq = total_timesteps # set to a high number to just save at end, curriclum saves on level up as well\n",
    "    Saver(\n",
    "        base_component = 'Model',\n",
    "        parent_method = 'end',\n",
    "        track_vars = [\n",
    "                    'model', \n",
    "                    #'replay_buffer', # this can cost alot of memory\n",
    "                    ],\n",
    "        write_folder = output_dir + 'modeling/',\n",
    "        save_config = True,\n",
    "        save_log = False,\n",
    "        order = 'post',\n",
    "        frequency = checkpoint_freq,\n",
    "        name = 'ModelingSaver',\n",
    "    )\n",
    "\n",
    "\n",
    "# CONNECT COMPONENTS\n",
    "configuration.connect_all()\n",
    "gm.speak('all components collected...')\n",
    "\n",
    "# WRITE CONFIGURATION\n",
    "configuration.save()\n",
    "\n",
    "# WRITE CONTROLLER\n",
    "controller.save(output_dir + 'train_controller.json')\n",
    "\n",
    "# RUN CONTROLLER\n",
    "gm.speak('running controller...')\n",
    "configuration.controller.run()\n",
    "\n",
    "# DISCONNECT\n",
    "configuration.disconnect_all()\n",
    "\n",
    "# done\n",
    "gm.speak('training complete! evaluating...')\n",
    "configuration.save()\n",
    "rm.evaluate_navi({\n",
    "    'config_path':f'{output_dir}configuration.json',\n",
    "    'model_path':f'{output_dir}modeling/model_final.zip',\n",
    "    'output_dir':f'{output_dir}test_final/',\n",
    "    'device':device,\n",
    "    'astar_name':'test',\n",
    "    'max_level':max_level,\n",
    "})\n",
    "rm.evaluate_navi({\n",
    "    'config_path':f'{output_dir}configuration.json',\n",
    "    'model_path':f'{output_dir}modeling/model_final.zip',\n",
    "    'output_dir':f'{output_dir}train_final/',\n",
    "    'device':device,\n",
    "    'astar_name':'train',\n",
    "    'max_level':max_level,\n",
    "})\n",
    "rm.evaluate_navi({\n",
    "    'config_path':f'{output_dir}configuration.json',\n",
    "    'model_path':f'{output_dir}modeling/model_final.zip',\n",
    "    'output_dir':f'{output_dir}all_final/',\n",
    "    'device':device,\n",
    "    'astar_name':'all',\n",
    "    'max_level':max_level,\n",
    "})\n",
    "gm.print_local_log()\n",
    "complete_path = gm.get_global('complete_path')\n",
    "gm.pk_write(True, complete_path)\n",
    "gm.progress(job_name, f'complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eec056-a9fa-41ae-bb53-d48d4a4ac795",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
