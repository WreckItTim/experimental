{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdd5d440",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a591cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.collections import PatchCollection\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import pickle\n",
    "#plt.rcParams.update({'font.size': 16})\n",
    "#plt.show() # need to call show so will update default params above\n",
    "# color blind friendly colors\n",
    "# https://gist.github.com/thriveth/8560036\n",
    "tableau_colors = mcolors.TABLEAU_COLORS\n",
    "color_dict = {name.split(':')[1]:tableau_colors[name] for name in tableau_colors}\n",
    "color_list = [color_dict[name] for name in color_dict]\n",
    "def get_color(idx):\n",
    "    return color_list[idx%len(color_list)]\n",
    "markers = [\n",
    "    '.',\n",
    "    'x',\n",
    "    '+',\n",
    "    '*',\n",
    "    '1',\n",
    "    '^',\n",
    "    's',\n",
    "    'd',\n",
    "    'H',\n",
    "    '3',\n",
    "    'o',\n",
    "]\n",
    "import sys\n",
    "dropbox_path = '/home/tim/Dropbox/'\n",
    "sys.path.append(dropbox_path)\n",
    "from commands.setup import *\n",
    "instance_name, dropbox_path, local_path, data_path, models_path = setup(dropbox_path=dropbox_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c798176-664c-407e-ad4e-41b416ebec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base map\n",
    "case_map = {\n",
    "    'a':{\n",
    "        'color':color_dict['blue'],\n",
    "        'marker':markers[0],\n",
    "    },\n",
    "    'b':{\n",
    "        'color':color_dict['orange'],\n",
    "        'marker':markers[1],\n",
    "    },\n",
    "    'c':{\n",
    "        'color':color_dict['green'],\n",
    "        'marker':markers[2],\n",
    "    },\n",
    "    'd':{\n",
    "        'color':color_dict['red'],\n",
    "        'marker':markers[3],\n",
    "    },\n",
    "    'e':{\n",
    "        'color':color_dict['purple'],\n",
    "        'marker':markers[4],\n",
    "    },\n",
    "    'f':{\n",
    "        'color':color_dict['brown'],\n",
    "        'marker':markers[5],\n",
    "    },\n",
    "    'g':{\n",
    "        'color':color_dict['pink'],\n",
    "        'marker':markers[6],\n",
    "    },\n",
    "    'h':{\n",
    "        'color':color_dict['gray'],\n",
    "        'marker':markers[7],\n",
    "    },\n",
    "    'i':{\n",
    "        'color':color_dict['olive'],\n",
    "        'marker':markers[8],\n",
    "    },\n",
    "    'j':{\n",
    "        'color':color_dict['cyan'],\n",
    "        'marker':markers[9],\n",
    "    },\n",
    "    'k':{\n",
    "        'color':color_dict['blue'],\n",
    "        'marker':markers[10],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01cb5af-867a-4997-9d23-4071e97678a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN_v2\n",
    "case_map['a']['label'], case_map['a']['val'] = 'DNN', 0\n",
    "case_map['b']['label'], case_map['b']['val'] = r'$X = 2$', 2\n",
    "case_map['c']['label'], case_map['c']['val'] = r'$X = 4$', 4\n",
    "case_map['d']['label'], case_map['d']['val'] = r'$X = 6$', 6\n",
    "case_map['e']['label'], case_map['e']['val'] = r'$X = 8$', 8\n",
    "case_map['f']['label'], case_map['f']['val'] = r'$X = 10$', 10\n",
    "case_map['g']['label'], case_map['g']['val'] = r'$X = 12$', 12\n",
    "case_map['h']['label'], case_map['h']['val'] = r'$X = 14$', 14\n",
    "case_map['i']['label'], case_map['i']['val'] = r'$X = 16$', 16\n",
    "case_map['j']['label'], case_map['j']['val'] = r'$X= 18$', 18\n",
    "case_map['k']['label'], case_map['k']['val'] = r'$X= 20$', 20\n",
    "\n",
    "airsim_map = 'AirSimNH'\n",
    "motion = '2d'\n",
    "project_name = 'Navi'\n",
    "experiment_name = 'DQN_v5'\n",
    "fetch_cases = list(case_map.keys())\n",
    "fetch_xlabels = [str(2*delta_x) for delta_x in range(10)]\n",
    "Xlabel = r'$X$ [meters]'\n",
    "fetch_version = 'v4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bc0f58-9ed5-4514-be97-a87102d57ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = []\n",
    "steps = []\n",
    "test_accuracys = []\n",
    "test_lengths = []\n",
    "levels = []\n",
    "Xs = []\n",
    "runs = []\n",
    "labels = []\n",
    "colors = []\n",
    "cases = []\n",
    "markers = []\n",
    "best_runs = {}\n",
    "for vi, version in enumerate([fetch_version]):\n",
    "    these_runs = []\n",
    "    for case in fetch_cases:\n",
    "        trial_name = f'{airsim_map}_{motion}_{version}_{case}'\n",
    "        runs_folder = models_path + '/'.join([project_name, experiment_name, trial_name])+'/'\n",
    "        if os.path.exists(runs_folder):\n",
    "            run_names = os.listdir(runs_folder)\n",
    "            for run_name in run_names:\n",
    "                if '.' in run_name:\n",
    "                    continue\n",
    "                run_num = int(run_name)\n",
    "                working_directory = runs_folder + run_name + '/'\n",
    "                \n",
    "                #configuration_path = working_directory + 'configuration.json'\n",
    "                #if not os.path.exists(configuration_path):\n",
    "                #    continue\n",
    "                #configuration = json.load(open(configuration_path, 'r'))\n",
    "                #nEpisodes = configuration['components']['Environment']['episode_counter']\n",
    "                #nSteps = configuration['components']['Environment']['step_counter']\n",
    "                #level = configuration['components']['Curriculum']['level']\n",
    "                \n",
    "                results_path = working_directory + 'results.json'\n",
    "                if not os.path.exists(results_path):\n",
    "                    continue\n",
    "                results = json.load(open(results_path, 'r'))\n",
    "                level = results['level'] + 1\n",
    "                nEpisodes = results['episodes']\n",
    "                nSteps = results['steps']\n",
    "                test_accuracy = results['test_accuracy']\n",
    "                test_length = results['test_length']\n",
    "\n",
    "                # evaluation_path = working_directory + 'test_final/evaluation.json'\n",
    "                # if os.path.exists(evaluation_path):\n",
    "                #     evaluation = json.load(open(evaluation_path, 'r'))\n",
    "                #     test_accuracy = 100*np.mean(evaluation['successes'])\n",
    "                #     test_length = np.mean(evaluation['lengths'])\n",
    "\n",
    "                if case not in best_runs:\n",
    "                    best_runs[case] = [run_name, test_accuracy]\n",
    "                if test_accuracy > best_runs[case][1]:\n",
    "                    best_runs[case] = [run_name, test_accuracy]\n",
    "\n",
    "                color, marker, label, val = case_map[case]['color'], case_map[case]['marker'], case_map[case]['label'], case_map[case]['val']\n",
    "                case_idx = fetch_cases.index(case)\n",
    "                \n",
    "                steps.append(nSteps)\n",
    "                cases.append(case)\n",
    "                labels.append(label)\n",
    "                markers.append(marker)\n",
    "                episodes.append(nEpisodes)\n",
    "                test_accuracys.append(test_accuracy)\n",
    "                test_lengths.append(test_length)\n",
    "                Xs.append(case_idx)\n",
    "                colors.append(color)\n",
    "                these_runs.append(run_name)\n",
    "                levels.append(level)\n",
    "    runs.append(these_runs)\n",
    "        \n",
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(8,8))\n",
    "\n",
    "ax = axs[0,0]\n",
    "time_stats = {case:[] for case in case_map}\n",
    "ax.set_title('Training Time')\n",
    "for i in range(len(Xs)):\n",
    "    time_stats[cases[i]].append(steps[i])\n",
    "    ax.scatter(Xs[i], np.log10(steps[i]), color=colors[i], marker=markers[i])\n",
    "ax.set_xticks([i for i in range(len(fetch_xlabels))], [xlabel for xlabel in fetch_xlabels], rotation=90)\n",
    "ax.set_xlabel(Xlabel)\n",
    "ax.set_ylabel('log$_{10}$(#Steps)')\n",
    "\n",
    "ax = axs[0,1]\n",
    "level_stats = {case:[] for case in case_map}\n",
    "ax.set_title('Curriculum Level')\n",
    "cased = {}\n",
    "for i in range(len(Xs)):\n",
    "    level_stats[cases[i]].append(levels[i])\n",
    "    if cases[i] not in cased:\n",
    "        ax.scatter(Xs[i], levels[i], color=colors[i], marker=markers[i], label=labels[i])\n",
    "        cased[cases[i]] = True\n",
    "    else:\n",
    "        ax.scatter(Xs[i], levels[i], color=colors[i], marker=markers[i])\n",
    "ax.set_xticks([i for i in range(len(fetch_xlabels))], [xlabel for xlabel in fetch_xlabels], rotation=90)\n",
    "ax.set_xlabel(Xlabel)\n",
    "ax.set_ylabel('#Levels')\n",
    "#ax.legend(loc='center left', fancybox=True, bbox_to_anchor=(-1, 1.4), ncols=3)\n",
    "fig.legend(bbox_to_anchor=(1, 1.05), ncols=len(cased))   \n",
    "\n",
    "ax = axs[1,0]\n",
    "acc_stats = {case:[] for case in case_map}\n",
    "ax.set_title('Navigation Accuracy')\n",
    "for i in range(len(Xs)):\n",
    "    acc_stats[cases[i]].append(test_accuracys[i])\n",
    "    ax.scatter(Xs[i], test_accuracys[i], color=colors[i], marker=markers[i])\n",
    "ax.set_xticks([i for i in range(len(fetch_xlabels))], [xlabel for xlabel in fetch_xlabels], rotation=90)\n",
    "ax.set_xlabel(Xlabel)\n",
    "ax.set_ylabel('%Goal')\n",
    "    \n",
    "ax = axs[1,1]\n",
    "length_stats = {case:[] for case in case_map}\n",
    "ax.set_title('Path Length')\n",
    "for i in range(len(Xs)):\n",
    "    length_stats[cases[i]].append(test_lengths[i])\n",
    "    ax.scatter(Xs[i], test_lengths[i], color=colors[i], marker=markers[i])\n",
    "ax.set_xticks([i for i in range(len(fetch_xlabels))], [xlabel for xlabel in fetch_xlabels], rotation=90)\n",
    "ax.set_xlabel(Xlabel)\n",
    "ax.set_ylabel('Ratio of #Steps to Astar')\n",
    "\n",
    "#plt.suptitle(f'same color = same random run')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8766f5dc-f38a-44f5-b058-4373f3b385f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read states\n",
    "# json files output with all string key names\n",
    "# process so that the evaluation dictionary structure is such:\n",
    "    # episode # - int\n",
    "        # step # - int\n",
    "            # state - dictionary of misc key, value pairs for that state\n",
    "def process_episodes(json_evaluation):\n",
    "    nEpisodes = len(json_evaluation)\n",
    "    episodes = [None] * nEpisodes\n",
    "    episode_idx = 0\n",
    "    for episode_str in json_evaluation:\n",
    "        if 'episode_' not in episode_str:\n",
    "            continue\n",
    "        json_episode = json_evaluation[episode_str]\n",
    "        nSteps = len(json_episode)\n",
    "        states = [None] * nSteps\n",
    "        for step_str in json_episode:\n",
    "            step_num = int(step_str.split('_')[1])\n",
    "            state = json_episode[step_str]\n",
    "            states[step_num] = state\n",
    "        episodes[episode_idx] = states\n",
    "        episode_idx += 1\n",
    "    return episodes\n",
    "def read_evaluations(evaluation_folder):\n",
    "    evaluation_files = [file for file in os.listdir(evaluation_folder) if 'states' in file]\n",
    "    nEvaluations = len(evaluation_files)\n",
    "    evaluations = [None] * nEvaluations\n",
    "    for evaluation_file in evaluation_files:\n",
    "        if '.json' not in evaluation_file:\n",
    "            continue\n",
    "        epoch = int(evaluation_file.split('.')[0].split('_')[-1])\n",
    "        #print(evaluation_file, epoch)\n",
    "        json_evaluation = json.load(open(evaluation_folder + evaluation_file, 'r'))\n",
    "        episodes = process_episodes(json_evaluation)\n",
    "        evaluations[epoch] = episodes\n",
    "    return evaluations\n",
    "# architecture for evaluations:\n",
    "# evaluations - list of episodes (indexed of evaluation number) - 0 idx is first evaluation\n",
    "    # episodes - list of states (indexed by step number)\n",
    "        # states - dict of (key, value) pairs for state at all_evaluations[instance][evaluation][episode][step]\n",
    "# read evaluations from each instance\n",
    "# each instance is a sub folder from parent with which this eval notebook is in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f0239a-7b3f-4ac0-b386-b933d6de61f7",
   "metadata": {},
   "source": [
    "# get all raw data results dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac0ed6d-251b-48b3-af3b-17ea92a4bb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "version = fetch_version\n",
    "\n",
    "# results dicts\n",
    "Inits = [] # global\n",
    "Xs = {} # case by case\n",
    "Accuracies = {} # case by case\n",
    "Terminations = {case:[] for case in best_runs} # path by path\n",
    "Madps = {case:[] for case in best_runs} # step by step\n",
    "\n",
    "# collect\n",
    "for case in best_runs:\n",
    "    run_name = best_runs[case][0]\n",
    "    trial_name = f'{airsim_map}_{motion}_{version}_{case}'\n",
    "    runs_folder = models_path + '/'.join([project_name, experiment_name, trial_name])+'/'\n",
    "    run_num = int(run_name)\n",
    "    working_directory = runs_folder + run_name + '/'\n",
    "\n",
    "    # case by case results\n",
    "    Xs[case] = case_map[case]['val']\n",
    "    Accuracies[case] = best_runs[case][1]\n",
    "\n",
    "    # iterate through each episode\n",
    "    states_path = f'{working_directory}test_final/states/'\n",
    "    episodes = read_evaluations(states_path)[0]\n",
    "    for episode_idx, episode in enumerate(episodes):\n",
    "        # path by path\n",
    "        init_state = episode[0]\n",
    "        if case == 'a':\n",
    "            Inits.append(init_state)\n",
    "        final_state = episode[-1]\n",
    "        Terminations[case].append(final_state['termination_reason'])\n",
    "        madps = []\n",
    "        madps.append(False)\n",
    "        for state in episode[1:-1]:\n",
    "            if case == 'a':\n",
    "                madps.append(False)\n",
    "            else:\n",
    "                madps.append(state['use_madp'])\n",
    "        Madps[case].append(madps)\n",
    "\n",
    "pickle.dump( {\n",
    "    'Xs':Xs,\n",
    "    'Inits':Inits,\n",
    "    'Accuracies':Accuracies,\n",
    "    'Madps':Madps,\n",
    "    'Terminations':Terminations,\n",
    "}, open(f'bank/figures/data/navi_results_{experiment_name}.p', 'wb'))\n",
    "          #  open(f'G:\\My Drive\\projects\\Project SmartDepth\\SmartDepth_shared\\figures\\data\\navi_results_{version}.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e219a033-26f5-4d82-983a-0ccc39a97bd0",
   "metadata": {},
   "source": [
    "# get all other metrics from each frame wrt to goals_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aa15b3-32e1-49f1-9cb6-ed49df821907",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = fetch_version\n",
    "for case in best_runs:\n",
    "    run_name = best_runs[case][0]\n",
    "    trial_name = f'{airsim_map}_{motion}_{version}_{case}'\n",
    "    runs_folder = models_path + '/'.join([project_name, experiment_name, trial_name])+'/'\n",
    "    run_num = int(run_name)\n",
    "    working_directory = runs_folder + run_name + '/'\n",
    "\n",
    "    states_path = f'{working_directory}test_final/states/'\n",
    "    episodes = read_evaluations(states_path)[0]\n",
    "    for episode_idx, episode in enumerate(episodes):\n",
    "        energies = power_dnn * time_dnn\n",
    "        _time = time_dnn\n",
    "        _powers = [power_dnn]\n",
    "        init_state = episode[0]\n",
    "        final_state = episode[-1]\n",
    "        nSteps = len(episode)\n",
    "        Steps[case][episode_idx] = nSteps\n",
    "        for state in episode[1:-1]:\n",
    "            use_madp = False\n",
    "            if 'use_madp' in state:\n",
    "                use_madp = state['use_madp']\n",
    "            if use_madp:\n",
    "                _powers.append(power_madp)\n",
    "                _energy += power_madp * time_madp\n",
    "                _time += time_madp\n",
    "            else:\n",
    "                _powers.append(power_dnn)\n",
    "                _energy += power_dnn * time_dnn\n",
    "                _time += time_dnn\n",
    "        Powers[case][episode_idx] = np.mean(_powers)\n",
    "        Energies[case][episode_idx] = _energy\n",
    "        Times[case][episode_idx] =_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333b188e-ef61-48e1-8e51-24154a86d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump({\n",
    "    'X':Xs,\n",
    "    'matches':matches,\n",
    "    'accuracy':Accs,\n",
    "    'length':Steps,\n",
    "    'time':Times,\n",
    "    'energy':Energies,\n",
    "    'power':Powers,\n",
    "}, open('navi_results.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b34434-2269-4e7b-b2eb-61c1634c57b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = fetch_version\n",
    "power_dnn = 23.88\n",
    "power_madp = 10.34\n",
    "time_dnn = 0.3882\n",
    "time_madp = 0.0103 \n",
    "Steps = {}\n",
    "Energies = {}\n",
    "Times = {}\n",
    "Powers = {}\n",
    "for case in best_runs:\n",
    "    run_name = best_runs[case][0]\n",
    "    trial_name = f'{airsim_map}_{motion}_{version}_{case}'\n",
    "    runs_folder = models_path + '/'.join([project_name, experiment_name, trial_name])+'/'\n",
    "    run_num = int(run_name)\n",
    "    working_directory = runs_folder + run_name + '/'\n",
    "    \n",
    "    results_path = working_directory + 'results.json'\n",
    "    results = json.load(open(results_path, 'r'))\n",
    "    level = results['level'] + 1\n",
    "    nEpisodes = results['episodes']\n",
    "    nSteps = results['steps']\n",
    "    test_accuracy = results['test_accuracy']\n",
    "    test_length = results['test_length']\n",
    "\n",
    "    states_path = f'{working_directory}test_final/states/'\n",
    "    episodes = read_evaluations(states_path)[0]\n",
    "\n",
    "    Steps[case] = {}\n",
    "    Energies[case] = {}\n",
    "    Times[case] = {}\n",
    "    Powers[case] = {}\n",
    "    test_idxs = matches['a']\n",
    "    for episode_idx, episode in enumerate(episodes):\n",
    "        if episode_idx not in test_idxs:\n",
    "            continue\n",
    "        _energy = power_dnn * time_dnn\n",
    "        _time = time_dnn\n",
    "        _powers = [power_dnn]\n",
    "        init_state = episode[0]\n",
    "        final_state = episode[-1]\n",
    "        nSteps = len(episode)\n",
    "        Steps[case][episode_idx] = nSteps\n",
    "        for state in episode[1:-1]:\n",
    "            use_madp = False\n",
    "            if 'use_madp' in state:\n",
    "                use_madp = state['use_madp']\n",
    "            if use_madp:\n",
    "                _powers.append(power_madp)\n",
    "                _energy += power_madp * time_madp\n",
    "                _time += time_madp\n",
    "            else:\n",
    "                _powers.append(power_dnn)\n",
    "                _energy += power_dnn * time_dnn\n",
    "                _time += time_dnn\n",
    "        Powers[case][episode_idx] = np.mean(_powers)\n",
    "        Energies[case][episode_idx] = _energy\n",
    "        Times[case][episode_idx] =_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c5b6e6-9db9-44f0-b4b6-e0bad34b0529",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump({\n",
    "    'X':Xs,\n",
    "    'matches':matches,\n",
    "    'accuracy':Accs,\n",
    "    'length':Steps,\n",
    "    'time':Times,\n",
    "    'energy':Energies,\n",
    "    'power':Powers,\n",
    "}, open('navi_results2.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8299b5-63c3-4c3a-b350-311d7ff21413",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = fetch_version\n",
    "power_dnn = 23.88\n",
    "power_madp = 10.34\n",
    "time_dnn = 0.3882\n",
    "time_madp = 0.0103 \n",
    "Steps = {}\n",
    "Energies = {}\n",
    "Times = {}\n",
    "Powers = {}\n",
    "for case in best_runs:\n",
    "    run_name = best_runs[case][0]\n",
    "    trial_name = f'{airsim_map}_{motion}_{version}_{case}'\n",
    "    runs_folder = models_path + '/'.join([project_name, experiment_name, trial_name])+'/'\n",
    "    run_num = int(run_name)\n",
    "    working_directory = runs_folder + run_name + '/'\n",
    "    \n",
    "    results_path = working_directory + 'results.json'\n",
    "    results = json.load(open(results_path, 'r'))\n",
    "    level = results['level'] + 1\n",
    "    nEpisodes = results['episodes']\n",
    "    nSteps = results['steps']\n",
    "    test_accuracy = results['test_accuracy']\n",
    "    test_length = results['test_length']\n",
    "\n",
    "    states_path = f'{working_directory}test_final/states/'\n",
    "    episodes = read_evaluations(states_path)[0]\n",
    "\n",
    "    Steps[case] = {}\n",
    "    Energies[case] = {}\n",
    "    Times[case] = {}\n",
    "    Powers[case] = {}\n",
    "    test_idxs = matches['a']\n",
    "    for episode_idx, episode in enumerate(episodes):\n",
    "        if episode_idx not in test_idxs:\n",
    "            continue\n",
    "        _energy = power_dnn * time_dnn\n",
    "        _time = time_dnn\n",
    "        _powers = [power_dnn]\n",
    "        init_state = episode[0]\n",
    "        final_state = episode[-1]\n",
    "        nSteps = len(episode)\n",
    "        Steps[case][episode_idx] = nSteps\n",
    "        for state in episode[1:-1]:\n",
    "            use_madp = False\n",
    "            if 'use_madp' in state:\n",
    "                use_madp = state['use_madp']\n",
    "            if use_madp:\n",
    "                _powers.append(power_madp)\n",
    "                _energy += power_madp * time_madp\n",
    "                _time += time_madp\n",
    "            else:\n",
    "                _powers.append(power_dnn)\n",
    "                _energy += power_dnn * time_dnn\n",
    "                _time += time_dnn\n",
    "        Powers[case][episode_idx] = _powers\n",
    "        Energies[case][episode_idx] = _energy\n",
    "        Times[case][episode_idx] =_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492ff7ab-a3f1-4351-bc25-101b084a539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump({\n",
    "    'X':Xs,\n",
    "    'matches':matches,\n",
    "    'accuracy':Accs,\n",
    "    'length':Steps,\n",
    "    'time':Times,\n",
    "    'energy':Energies,\n",
    "    'power':Powers,\n",
    "}, open('navi_results2.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135d91bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(8,8))\n",
    "fig.suptitle('Histograms over all runs')\n",
    "\n",
    "ax = axs[0,0]\n",
    "for case in time_stats:\n",
    "    ax.hist(time_stats[case], label=case_map[case]['label'], alpha = 0.5, color=case_map[case]['color'])\n",
    "    ax.set_xlabel('# of Training Episodes')\n",
    "    ax.set_ylabel('bin count')\n",
    "    #ax.set_title('Histogram over all runs')\n",
    "    ax.legend()\n",
    "\n",
    "ax = axs[0,1]\n",
    "for case in level_stats:\n",
    "    ax.hist(level_stats[case], label=case_map[case]['label'], alpha = 0.5, color=case_map[case]['color'])\n",
    "    ax.set_xlabel('Highest Reached Curriculum Level')\n",
    "    ax.set_ylabel('bin count')\n",
    "    #ax.set_title('Histogram over all runs')\n",
    "    #ax.legend()\n",
    "\n",
    "ax = axs[1,0]\n",
    "for case in acc_stats:\n",
    "    ax.hist(acc_stats[case], label=case_map[case]['label'], alpha = 0.5, color=case_map[case]['color'])\n",
    "    ax.set_xlabel('% Navigation Accuracy')\n",
    "    ax.set_ylabel('bin count')\n",
    "    #ax.set_title('Histogram over all runs')\n",
    "    #ax.legend()\n",
    "\n",
    "ax = axs[1,1]\n",
    "for case in length_stats:\n",
    "    ax.hist(length_stats[case], label=case_map[case]['label'], alpha = 0.5, color=case_map[case]['color'])\n",
    "    ax.set_xlabel('Path Length = *Astar Truth')\n",
    "    ax.set_ylabel('bin count')\n",
    "    #ax.set_title('Histogram over all runs')\n",
    "    #ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eec056-a9fa-41ae-bb53-d48d4a4ac795",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
