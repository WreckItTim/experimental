{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cc6514-706f-4fbe-9740-1460bbcaa1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 0\n",
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "import os\n",
    "home_dir = '/home/tim/Dropbox/' # home directory of repo downloaded from github\n",
    "sys.path.append(home_dir)\n",
    "from global_methods import *\n",
    "from analytics_methods import *\n",
    "from shortest_path.shortest_methods import *\n",
    "from data.data_methods import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1997f2dd-ffa6-41cd-b8d0-bffdc2c913e5",
   "metadata": {},
   "source": [
    "# set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ead1d68-67a4-452e-9556-28142b283e4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set parent path to directory where data is stored (with observations as a subdirectory in this parent dir)\n",
    "data_dir = '/home/tim/Dropbox/data/'\n",
    "\n",
    "\n",
    "# **** the parameters below are static values for your reference, select from these to use in below cells\n",
    "\n",
    "# will display data from these sensors in subplots later, in order from top-to-bottom left-to-right\n",
    "# bounding boxes will be drawn on the previous sensor in list\n",
    "sensor_names_all = [\n",
    "    'SceneV1', # forward RGB scene (sunny, no weather) 144x256 resolution\n",
    "    'BoxesV1', # ground truth bounding boxes of all objects in scene, will be drawn onto sensor above this\n",
    "    'SegmentationV1', # ground truth color forward segementation 144x256 resolution\n",
    "    'MasksV1', # ground truth dictionary of boolean array masks for each object in scene\n",
    "    'DepthV1', # ground truth forward depth 144x256 resolution\n",
    "    'DepthV2', # ground truth forward depth 36x64 resolution \n",
    "    'SceneV3', # forward RGB rain 144x256 resolution\n",
    "    'SceneV4', # forward RGB snow 144x256 resolution\n",
    "    'SceneV5', # forward RGB fog 144x256 resolution\n",
    "]\n",
    "\n",
    "# id_names are a unique identifier to tag specific subsets or versions of a data_dict\n",
    "id_names_all = [\n",
    "    'alpha', # most current stable data\n",
    "    'beta', # experimental data -- will update to alpha when finished\n",
    "    'demo', # quickly collected data to show\n",
    "]\n",
    "\n",
    "# these are valid ranges of coordinates that you can use\n",
    "    # train is top half, test is bottom half, all is both halves\n",
    "x_vals_train_blocks = [x for x in range(-60, 101, 2)]\n",
    "x_vals_test_blocks = [x for x in range(-120, 1, 2)]\n",
    "x_vals_all_blocks = [x for x in range(-120, 101, 2)]\n",
    "y_vals_all_blocks = [y for y in range(-140, 141, 2)]\n",
    "x_vals_train_airsimnh = [x for x in range(-10, 241, 2)]\n",
    "x_vals_test_airsimnh = [x for x in range(-240, 11, 2)]\n",
    "x_vals_all_airsimnh = [x for x in range(-240, 241, 2)]\n",
    "y_vals_all_airsimnh = [y for y in range(-240, 241, 2)]\n",
    "z_vals_2d, z_vals_3d = [-4], [-4] #[-16, -12, -8, -4] # working on z-vals outside of -4\n",
    "yaw_vals_all = [0, 1, 2, 3]\n",
    "#t_vals_all = [0] # working on temporal values to add to dictionary \n",
    "\n",
    "# rename titles on subplots in animation\n",
    "sensor_psuedonames = {\n",
    "    'DepthV1':'Depth', # forward depth 144x256 resolution\n",
    "    'DepthV2':'Depth Downsampled', # forward depth 144x256 resolution\n",
    "    'SceneV1':'RGB', # forward RGB 144x256 resolution\n",
    "    'SceneV3':'Rain', # forward RGB rain 144x256 resolution\n",
    "    'SceneV4':'Snow', # forward RGB snow 144x256 resolution\n",
    "    'SceneV5':'Fog', # forward RGB fog 144x256 resolution\n",
    "    'SegmentationV1':'Segmentation', # forward RGB fog 144x256 resolution\n",
    "    'MasksV1':'Object Mask', # splits each individual object into bool array\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f52ca9-bbc3-45f5-b85f-dc93cd94ce5b",
   "metadata": {},
   "source": [
    "# fetch and view data at a specific set of x, y, z, yaw coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21be658-6b0f-433d-8fbb-efc61699d7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set coordinate ranges\n",
    "x_vals = [x for x in range(-32, 32, 2)]\n",
    "y_vals = [y for y in range(0, 2, 2)]\n",
    "z_vals = [z for z in range(-4, 0, 4)]\n",
    "yaw_vals = [0]\n",
    "airsim_map = 'AirSimNH'\n",
    "sensor_names = [\n",
    "    'SceneV1',\n",
    "    # 'BoxesV1',\n",
    "    # 'SceneV3',\n",
    "    # 'SceneV4',\n",
    "    # 'SceneV5',\n",
    "    'DepthV1',\n",
    "    #'DepthV2',\n",
    "    # 'SegmentationV1',\n",
    "    # 'MasksV1',\n",
    "]\n",
    "id_names = ['alpha'] # only use stable data\n",
    "resolution=[144,256] # height, width of observation arrays (images)\n",
    "\n",
    "# fetch data from coordinates\n",
    "location_data, location_animation = data_at_coordinates(airsim_map, sensor_names, id_names, x_vals, y_vals, z_vals, yaw_vals, \n",
    "                    make_animation=True, return_data=True, ncols=3, additional_subplots=0, resolution=resolution, sensor_psuedonames=sensor_psuedonames)\n",
    "\n",
    "# display results\n",
    "display_data_results(location_data, location_animation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84caf739-4396-46f9-b092-ed82f0207cc3",
   "metadata": {},
   "source": [
    "# read paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dda33a-2cb5-4c03-bdd4-c189ccc189a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_path = f'{data_dir}astar_paths/v1/AirSimNH_2d_test.p'\n",
    "paths_info, n_total_paths = load_paths(paths_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b971f78b-2035-48af-97f9-7e825b14c9fb",
   "metadata": {},
   "source": [
    "# view data along a predetermined random Astar path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbc6da1-84d0-4746-a464-54a428b5b75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to view (paths are ordered in increasing difficulty / length\n",
    "path = paths_info['paths'][n_total_paths-16] # -16 is just a default arbitrary path I like\n",
    "airsim_map = 'AirSimNH'\n",
    "sensor_names = [\n",
    "    'SceneV1',\n",
    "    'BoxesV1',\n",
    "    'SceneV3',\n",
    "    'SceneV4',\n",
    "    'SceneV5',\n",
    "    'DepthV1',\n",
    "    #'DepthV2',\n",
    "    'SegmentationV1',\n",
    "    'MasksV1',\n",
    "]\n",
    "id_names = ['alpha'] # only use stable data\n",
    "resolution=[144,256] # height, width of observation arrays (images)\n",
    "\n",
    "path_data, path_animation = data_at_path(data_dir, airsim_map, sensor_names, id_names, path, \n",
    "                 make_animation=True, return_data=True, ncols = 3, resolution=resolution, \n",
    "                 sensor_psuedonames=sensor_psuedonames, include_nulls=False)\n",
    "\n",
    "# display results\n",
    "display_data_results(path_data, path_animation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ce3ec9-d310-4b9a-8e8b-1f10cb5006ce",
   "metadata": {},
   "source": [
    "# determine path between desired start/target point and view data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fe363a-f66b-4ae7-bab2-fcb2493671f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion = '2d' # 2d for horizontal plane only, 3d to allow drone to move up and down\n",
    "start = [0, -80, -4] # x, y, z\n",
    "target = [-80, 0, -4] # x, y, z\n",
    "path = get_astar_path(motion, airsim_map, start, target)\n",
    "\n",
    "# view data along path\n",
    "path_data2, path_animation2 = data_at_path(data_dir, airsim_map, sensor_names, id_names, path, \n",
    "                 make_animation=True, return_data=True, ncols = 3, resolution=resolution, \n",
    "                 sensor_psuedonames=sensor_psuedonames, include_nulls=False)\n",
    "\n",
    "# display results\n",
    "display_data_results(path_data2, path_animation2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f8cf28-4982-4d39-9f68-489f6c79c4da",
   "metadata": {},
   "source": [
    "# visualize test path(s) taken from a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a847cff4-7c4b-4778-a345-a167b0c485c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "airsim_map = 'Blocks'\n",
    "motion = '2d'\n",
    "model_dir = f'{home_dir}models/navigation_airsim_blocks_dqn_2d/'\n",
    "test_dir = f'{model_dir}test_final/'\n",
    "configuration_path = f'{model_dir}configuration.json'\n",
    "configuration = json.load(open(configuration_path, 'r'))\n",
    "actions = configuration['components']['Actor']['actions_components'] # list of actions DQN can take\n",
    "episodes = read_evaluations(f'{test_dir}states/')[0]\n",
    "sensor_names = ['DepthV2'] # sensor data to view at each step\n",
    "resolution = [36, 64] # highest resolution of image data to display [height, width]\n",
    "id_names = ['alpha'] # id of which data to use (alpha is stable build)\n",
    "\n",
    "# view data at given episode\n",
    "episode_idx = 777\n",
    "episode = episodes[episode_idx]\n",
    "episode_data, episode_animation = data_at_episode(data_dir, airsim_map, sensor_names, id_names, \n",
    "                                      episode, actions, make_animation=True, return_data=True,\n",
    "                                                 resolution=resolution, \n",
    "                                                  sensor_psuedonames=sensor_psuedonames)\n",
    "\n",
    "# display results\n",
    "display_data_results(episode_data, episode_animation)\n",
    "\n",
    "episode_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ad579-5267-472d-9dcb-bdfada5896b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
