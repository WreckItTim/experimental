{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72188bc6-912c-4b42-a64f-06a9be07c725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_dir = '/home/tim/Dropbox/experimental/' # your path here where to parent directory where repos are\n",
    "local_dir = '/home/tim/local/'\n",
    "os.chdir(root_dir)\n",
    "import sys\n",
    "sys.path.append(root_dir)\n",
    "import map_data.map_methods as mm\n",
    "import supervised_learning.supervised_methods as sm\n",
    "from supervised_learning.slim_methods import SlimConv2d, SlimBatchNorm2d, SlimConvTranspose2d\n",
    "from supervised_learning.slim_methods import forward_slim_train, forward_slim_val, foward_slim_predictions\n",
    "from torch import nn\n",
    "import utils.global_methods as gm\n",
    "import sys\n",
    "import matplotlib.cm as cm\n",
    "import torch as th\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from matplotlib import colors as mcolors\n",
    "import multiprocessing as mp\n",
    "initial_locals = locals().copy() # will exclude these parameters from config parameters written to file\n",
    "\n",
    "# read params from command line\n",
    "random_seed = 42\n",
    "scale = 1 # scales number of channels in each layer\n",
    "job_name = 'null'\n",
    "device = 'cuda:0'\n",
    "pytorch_threads = 8 # scale this down with more active processes running at same time\n",
    "num_workers = 2 # scale this down with RAM constraints\n",
    "batch_size = 16 # scale this down with VRAM constraints\n",
    "pin_memory = False # toggle on if training data is small enough to fit in VRAM\n",
    "overwrite = False # will clear all files in run_dir and restart everything from square 1\n",
    "continue_training = True # will check if checkpoint files exist and load them and continue training if they do\n",
    "scale = 1 # multiply the number of channels in the original depth network size by this\n",
    "use_slim_cnn = False # True will make neural network with custom slim layers\n",
    "use_slim_train = False # True will use custom forward_slim_...\n",
    "use_slim_soft = False # True will add soft targets to loss function\n",
    "rhos = [0.25, 0.5, 1.0]\n",
    "version = 'v0'\n",
    "train_sample_size = 10_000 # number of data instances to fetch (None to use all available)\n",
    "test_sample_size = 10_000 # number of data instances to fetch (None to use all available)\n",
    "patience = 10\n",
    "max_epochs = 100\n",
    "model_structure = 'DGNLNet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7202a16a-253c-4e27-92da-90dede22b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'V2_scale_dummy'\n",
    "scale = 4\n",
    "random_seed = 3\n",
    "use_slim_cnn = True\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df874373-ab82-4925-9016-382de9cb5082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directory to write all results to\n",
    "run_dir = f'{root_dir}models/monocular_depth/{version}/seed_{random_seed}/'\n",
    "os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "# save all params to file\n",
    "all_locals = locals()\n",
    "new_locals = {k:v for k, v in all_locals.items() if (not k.startswith('__') and k not in initial_locals and k not in ['initial_locals','all_locals'])}\n",
    "params = new_locals.copy()\n",
    "gm.pk_write(params, f'{run_dir}params.p')\n",
    "\n",
    "# output job start\n",
    "print('running job with params', params)\n",
    "gm.set_global('local_dir', local_dir)\n",
    "gm.progress(job_name, 'started')\n",
    "\n",
    "# the numpy arrays need to match the same floating type used by pytorch here\n",
    "th.set_default_dtype(th.float32)\n",
    "\n",
    "# remove some annoying tensorflow logging\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# set random seeds for replicability\n",
    "gm.set_random_seed(random_seed)\n",
    "\n",
    "# WARNING --- set file io -- will write model and evalutions to below paths (WILL OVERWRITE SAVED DATA, change if not desirable)\n",
    "save_model_to = f'{run_dir}model.pth'\n",
    "save_train_metrics_to = f'{run_dir}train_metrics.json'\n",
    "save_eval_metrics_to = f'{run_dir}eval_metrics.json'\n",
    "\n",
    "if not overwrite and os.path.exists(f'{run_dir}r2s.p'):\n",
    "    gm.progress(job_name, 'already completed')\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa6e4dc-7f18-4588-971f-f909289e3348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data = mm.get_data(\n",
    "    map_name = 'AirSimNH', # this is the neighorhood map with houses and cars and roads and stuff -- airsim_map can equal 'Blocks' or 'AirSimNH'\n",
    "    sensor_names = [ # name of sensors to fetch data, see README for available sensors -- names such as 'SceneV1' and 'SegmentationV1'\n",
    "        'SceneV1',  # SceneV1 is monocular forward facing RGB at 144x256 resolution\n",
    "        'DepthV1',  # DepthV1 is forward facing 2d depth map at 144x256 resolution\n",
    "    ],\n",
    "    region = 'train', # training is done on the top half of the map -- region can equal 'train' 'test' or 'all'\n",
    "    sample_size = train_sample_size, # number of data instances to fetch (None to use all available)\n",
    ")\n",
    "X = data['observations']['SceneV1'] # RGB\n",
    "Y = data['observations']['DepthV1'] # to depth\n",
    "coordinates = data['coordinates'] # list of x, y, z, yaw coordinates at each index corresponding to data\n",
    "\n",
    "# split into train and validation sets\n",
    "percent_train, percent_val = 0.8, 0.2\n",
    "N = len(coordinates)\n",
    "n_train, n_val = int(percent_train*N), int(percent_val*N)\n",
    "if n_val > 0:\n",
    "    X_train = X[:n_train]\n",
    "    Y_train = Y[:n_train]\n",
    "    X_val = X[n_train:]\n",
    "    Y_val = Y[n_train:]\n",
    "else:\n",
    "    X_train = X\n",
    "    Y_train = Y\n",
    "    X_val = None\n",
    "    Y_val = None\n",
    "\n",
    "# extract parameters from input/ouput data\n",
    "n_input_channels = X_train.shape[1] # this is used in code below to make CNN model\n",
    "\n",
    "print('Train shape:', X_train.shape, Y_train.shape)\n",
    "if n_val > 0:\n",
    "    print('Val shape:', X_val.shape, Y_val.shape)\n",
    "\n",
    "\n",
    "X_mean = 94.11807077041952 #np.mean(X_train)\n",
    "X_std = 80.77841523336176 #np.std(X_train)\n",
    "Y_min = 0\n",
    "Y_max = 255\n",
    "\n",
    "def x_preproc_func(x, _mean, _std):\n",
    "    return (x.astype(np.float32)-_mean)/_std\n",
    "def y_preproc_func(y, _min, _max):\n",
    "    return (y.astype(np.float32)-_min)/(_max-_min)\n",
    "x_preproc_params={'_mean':X_mean, '_std':X_std}\n",
    "y_preproc_params={'_min':Y_min, '_max':Y_max}\n",
    "def unprocess_func(p, _min, _max):\n",
    "    p = (p*(_max-_min)+_min)\n",
    "    p[p<=1] = 1\n",
    "    p[p>=255] = 255\n",
    "    p = p.astype(np.uint8)\n",
    "    return p\n",
    "unprocess_params={'_min':Y_min, '_max':Y_max}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f904c3-1696-4f2b-b41c-054b5edc2558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add custom cnn layers to network?\n",
    "if use_slim_cnn:\n",
    "    Conv2d = SlimConv2d\n",
    "    BatchNorm2d = SlimBatchNorm2d\n",
    "    ConvTranspose2d = SlimConvTranspose2d\n",
    "    in_channels_key = 'max_in_channels'\n",
    "    out_channels_key = 'max_out_channels'\n",
    "else:\n",
    "    Conv2d = nn.Conv2d\n",
    "    BatchNorm2d = nn.BatchNorm2d\n",
    "    ConvTranspose2d = nn.ConvTranspose2d\n",
    "    in_channels_key = 'in_channels'\n",
    "    out_channels_key = 'out_channels'\n",
    "\n",
    "# make scalable network structures\n",
    "# DGNLNet https://ieeexplore.ieee.org/abstract/document/9318521\n",
    "if model_structure in ['DGNLNet']:\n",
    "    model_func = sm.create_cnn # this is my custom method for creating a CNN (of couse you do not have to use it)\n",
    "    model_params = {\n",
    "        'block_layers':[\n",
    "                [\n",
    "                    [Conv2d, {in_channels_key:n_input_channels, out_channels_key:int(32*scale), 'kernel_size':4, 'stride':2, 'padding':1}],\n",
    "                    [BatchNorm2d, {'max_channels':int(32*scale), 'rhos':rhos} if use_slim_cnn else {'num_features':int(32*scale)}],\n",
    "                    [nn.SELU],\n",
    "                ],\n",
    "                [\n",
    "                    [Conv2d, {in_channels_key:int(32*scale), out_channels_key:int(64*scale), 'kernel_size':4, 'stride':2, 'padding':1}],\n",
    "                    [BatchNorm2d, {'max_channels':int(64*scale), 'rhos':rhos} if use_slim_cnn else {'num_features':int(64*scale)}],\n",
    "                    [nn.SELU],\n",
    "                ],\n",
    "                [\n",
    "                    [Conv2d, {in_channels_key:int(64*scale), out_channels_key:int(128*scale), 'kernel_size':4, 'stride':2, 'padding':1}],\n",
    "                    [BatchNorm2d, {'max_channels':int(128*scale), 'rhos':rhos} if use_slim_cnn else {'num_features':int(128*scale)}],\n",
    "                    [nn.SELU],\n",
    "                ],\n",
    "                [\n",
    "                    [Conv2d, {in_channels_key:int(128*scale), out_channels_key:int(256*scale), 'kernel_size':4, 'stride':2, 'padding':1}],\n",
    "                    [BatchNorm2d, {'max_channels':int(256*scale), 'rhos':rhos} if use_slim_cnn else {'num_features':int(256*scale)}],\n",
    "                    [nn.SELU],\n",
    "                ],\n",
    "                [\n",
    "                    [Conv2d, {in_channels_key:int(256*scale), out_channels_key:int(256*scale), 'kernel_size':3, 'dilation':2, 'padding':2}],\n",
    "                    [BatchNorm2d, {'max_channels':int(256*scale), 'rhos':rhos} if use_slim_cnn else {'num_features':int(256*scale)}],\n",
    "                    [nn.SELU],\n",
    "                ],\n",
    "                [\n",
    "                    [Conv2d, {in_channels_key:int(256*scale), out_channels_key:int(256*scale), 'kernel_size':3, 'dilation':4, 'padding':4}],\n",
    "                    [BatchNorm2d, {'max_channels':int(256*scale), 'rhos':rhos} if use_slim_cnn else {'num_features':int(256*scale)}],\n",
    "                    [nn.SELU],\n",
    "                ],\n",
    "                [\n",
    "                    [Conv2d, {in_channels_key:int(256*scale), out_channels_key:int(256*scale), 'kernel_size':3, 'dilation':2, 'padding':2}],\n",
    "                    [BatchNorm2d, {'max_channels':int(256*scale), 'rhos':rhos} if use_slim_cnn else {'num_features':int(256*scale)}],\n",
    "                    [nn.SELU],\n",
    "                ],\n",
    "                [\n",
    "                    [ConvTranspose2d, {in_channels_key:int(256*scale), out_channels_key:int(128*scale), 'kernel_size':4, 'stride':2, 'padding':1}],\n",
    "                    [BatchNorm2d, {'max_channels':int(128*scale), 'rhos':rhos} if use_slim_cnn else {'num_features':int(128*scale)}],\n",
    "                    [nn.SELU],\n",
    "                ],\n",
    "                [\n",
    "                    [ConvTranspose2d, {in_channels_key:int(128*scale), out_channels_key:int(64*scale), 'kernel_size':4, 'stride':2, 'padding':1}],\n",
    "                    [BatchNorm2d, {'max_channels':int(64*scale), 'rhos':rhos} if use_slim_cnn else {'num_features':int(64*scale)}],\n",
    "                    [nn.SELU],\n",
    "                ],\n",
    "                [\n",
    "                    [ConvTranspose2d, {in_channels_key:int(64*scale), out_channels_key:int(32*scale), 'kernel_size':4, 'stride':2, 'padding':1}],\n",
    "                    [BatchNorm2d, {'max_channels':int(32*scale), 'rhos':rhos} if use_slim_cnn else {'num_features':int(32*scale)}],\n",
    "                    [nn.SELU],\n",
    "                ],\n",
    "                [\n",
    "                    [ConvTranspose2d, {in_channels_key:int(32*scale), out_channels_key:int(32*scale), 'kernel_size':4, 'stride':2, 'padding':1}],\n",
    "                    [BatchNorm2d, {'max_channels':int(32*scale), 'rhos':rhos} if use_slim_cnn else {'num_features':int(32*scale)}],\n",
    "                    [nn.SELU],\n",
    "                    [Conv2d, {in_channels_key:int(32*scale), out_channels_key:int(32*scale), 'kernel_size':3, 'padding':1}],\n",
    "                    [nn.SELU],\n",
    "                    [Conv2d, {in_channels_key:int(32*scale), out_channels_key:int(1), 'kernel_size':1, 'stride':1, 'padding':0}],\n",
    "                    [nn.Sigmoid],\n",
    "                ],\n",
    "           ]\n",
    "    }\n",
    "    if use_slim_cnn:\n",
    "        model_params['block_layers'][0][0][1]['slim_in'] = False\n",
    "        model_params['block_layers'][-1][-2][1]['slim_out'] = False\n",
    "        \n",
    "\n",
    "model = model_func(**model_params)\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3639b079-24bf-4fb1-998d-11b040b1f002",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_train_func = sm.forward_train\n",
    "forward_train_extra_params = {}\n",
    "forward_val_func = sm.forward_val\n",
    "forward_val_extra_params = {}\n",
    "if use_slim_train:\n",
    "    forward_train_func = forward_slim_train\n",
    "    forward_train_extra_params = {'rhos':rhos, 'soft_targets':use_slim_soft}\n",
    "    forward_val_func = forward_slim_val\n",
    "    forward_val_extra_params = {'rhos':rhos}\n",
    "\n",
    "model, train_losses, val_losses, epoch_times = sm.one_shot(model_func, model_params, run_dir, X_train, Y_train, X_val, Y_val, \n",
    "             optimizier_func=th.optim.Adam, optimizer_params={}, minimize_error=True, criterion=nn.L1Loss(), \n",
    "             patience=patience, max_epochs=1, augmentors=None, sample_size=None, device=device, batch_size=batch_size, \n",
    "             pytorch_threads=pytorch_threads, num_workers=num_workers, pin_memory=pin_memory, checkpoint_freq=1, \n",
    "             random_seed=random_seed, show_curve_freq=0, continue_training=continue_training,\n",
    "             x_preproc_func=x_preproc_func, x_preproc_params=x_preproc_params, \n",
    "             y_preproc_func=y_preproc_func, y_preproc_params=y_preproc_params, \n",
    "             forward_train_func=forward_train_func, forward_train_extra_params=forward_train_extra_params,\n",
    "             forward_val_func=forward_val_func, forward_val_extra_params=forward_val_extra_params,\n",
    "            )\n",
    "\n",
    "th.save(model, save_model_to)\n",
    "\n",
    "train_metrics = {\n",
    "    'train_losses':train_losses, \n",
    "    'val_losses':val_losses, \n",
    "    'epoch_times':epoch_times,\n",
    "    'train_time':float(np.sum(epoch_times)),\n",
    "    'n_epochs':len(epoch_times)-1,\n",
    "}\n",
    "gm.write_json(train_metrics, save_train_metrics_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d2d483-9c69-4f36-8a07-6335608a1ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_slim_cnn:\n",
    "    r2s = {'train':{}, 'val':{}, 'test':{}}\n",
    "else:\n",
    "    r2s = {}\n",
    "\n",
    "def eval_set(X, Y, set_name):\n",
    "    DL = sm.preproc2(X, batch_size=batch_size, num_workers=num_workers,\n",
    "                      x_preproc_func=x_preproc_func, x_preproc_params=x_preproc_params,\n",
    "                    )\n",
    "    if use_slim_cnn:\n",
    "        Pslim = foward_slim_predictions(model, DL, device, rhos=rhos)\n",
    "        for rho in rhos:\n",
    "            r2s[set_name][rho] = sm.r2_score(Y, unprocess_func(Pslim[rho], **unprocess_params).astype(np.float32))\n",
    "    else:\n",
    "        P = sm.forward_predictions(model, DL, device)\n",
    "        r2s[set_name] = sm.r2_score(Y, unprocess_func(P, **unprocess_params).astype(np.float32))\n",
    "\n",
    "# eval train/val data\n",
    "eval_set(X_train, Y_train, 'train')\n",
    "del X_train\n",
    "del Y_train\n",
    "eval_set(X_val, Y_val, 'val')\n",
    "del X_val\n",
    "del Y_val\n",
    "del data\n",
    "mm.clear_cache()\n",
    "\n",
    "# eval test data\n",
    "data = mm.get_data(\n",
    "    map_name = 'AirSimNH', # this is the neighorhood map with houses and cars and roads and stuff -- airsim_map can equal 'Blocks' or 'AirSimNH'\n",
    "    sensor_names = [ # name of sensors to fetch data, see README for available sensors -- names such as 'SceneV1' and 'SegmentationV1'\n",
    "        'SceneV1',  # SceneV1 is monocular forward facing RGB at 144x256 resolution\n",
    "        'DepthV1',  # DepthV1 is forward facing 2d depth map at 144x256 resolution\n",
    "    ],\n",
    "    region = 'all', # region can equal 'train' 'test' or 'all'\n",
    "                               # or 'houses_{train/test/all}' for only the center portion of the map \n",
    "    sample_size = test_sample_size, # number of data instances to fetch (None to use all available)\n",
    "    pull_from_end = True, # sample from end of pre-shuffled data points to keep holdout test set seperate\n",
    ")\n",
    "X_test = data['observations']['SceneV1'] # RGB\n",
    "Y_test = data['observations']['DepthV1'] # to depth\n",
    "coordinates_eval = data['coordinates']\n",
    "eval_set(X_test, Y_test, 'test')\n",
    "del X_test\n",
    "del Y_test\n",
    "del data\n",
    "mm.clear_cache()\n",
    "\n",
    "gm.pk_write(r2s, f'{run_dir}r2s.p')\n",
    "\n",
    "gm.progress(job_name, 'complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0d02b9-5834-4fdc-a40c-c59f7a1cf814",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6442fe-90ce-45d4-9a61-4aee561f2dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
