{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e70c0da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from stable_baselines3 import TD3 as sb3TD3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from hyperopt import fmin, tpe, hp\n",
    "import pickle\n",
    "from torch import Tensor\n",
    "# simple stopwatch to time whatevs, in (float) seconds\n",
    "# keeps track of laps along with final time\n",
    "class Stopwatch:\n",
    "    def __init__(self):\n",
    "            self.start_time = time()\n",
    "            self.last_time = self.start_time\n",
    "            self.laps = []\n",
    "    def lap(self):\n",
    "        this_time = time()\n",
    "        delta_time = this_time - self.last_time\n",
    "        self.laps.append(delta_time)\n",
    "        self.last_time = this_time\n",
    "        return delta_time\n",
    "    def stop(self):\n",
    "        self.stop_time = time()\n",
    "        self.delta_time = self.stop_time - self.start_time\n",
    "        return self.delta_time\n",
    "class Slim(nn.Linear):\n",
    "    def __init__(self, max_in_features: int, max_out_features: int, bias: bool = True,\n",
    "                 device=None, dtype=None,\n",
    "                slim_in=True, slim_out=True) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__(max_in_features, max_out_features, bias, device, dtype)\n",
    "        self.max_in_features = max_in_features\n",
    "        self.max_out_features = max_out_features\n",
    "        self.slim_in = slim_in\n",
    "        self.slim_out = slim_out\n",
    "        self.slim = 1\n",
    "        \n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        if self.slim_in:\n",
    "            self.in_features = int(self.slim * self.max_in_features)\n",
    "        if self.slim_out:\n",
    "            self.out_features = int(self.slim * self.max_out_features)\n",
    "        weight = self.weight[:self.out_features, :self.in_features]\n",
    "        if self.bias is not None:\n",
    "            bias = self.bias[:self.out_features]\n",
    "        else:\n",
    "            bias = self.bias\n",
    "        y = F.linear(input, weight, bias)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aabcb569",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data_beta/' # horizontal, 25x25 forward and belly depths\n",
    "observations = {}\n",
    "files = os.listdir(data_dir)\n",
    "for fname in files:\n",
    "    fpath = data_dir + fname\n",
    "    if 'observations' in fname:\n",
    "        observation_set = np.load(fpath, allow_pickle=True)\n",
    "        observations.update(observation_set)\n",
    "Xs = {\n",
    "    'train':[],\n",
    "    'val':[],\n",
    "    'test':[],\n",
    "}\n",
    "Ys = {\n",
    "    'train':[],\n",
    "    'val':[],\n",
    "    'test':[],\n",
    "}\n",
    "XYs = {\n",
    "    'train':[],\n",
    "    'val':[],\n",
    "    'test':[],\n",
    "}\n",
    "Qs = {\n",
    "    'train':[],\n",
    "    'val':[],\n",
    "    'test':[],\n",
    "}\n",
    "\n",
    "# distance normalization parameters\n",
    "min_input = 125/1000 # min depth (below this is erroneous)\n",
    "max_input = 125 # max depth\n",
    "min_output = 0.1 # reserve 0 for no-data\n",
    "max_output = 1 \n",
    "left = 0 # set all values below range to this\n",
    "right = None\n",
    "\n",
    "nSteps = []\n",
    "for fname in files:\n",
    "    fpath = data_dir + fname\n",
    "    if 'states' in fname:\n",
    "        jdict = json.load(open(fpath, 'r'))\n",
    "        for episode in jdict:\n",
    "            gfile = jdict[episode]['step_0']['fname']\n",
    "            if 'part2' in gfile or 'part3' in gfile or 'vertical' in gfile:\n",
    "                continue\n",
    "            if 'train' in gfile:\n",
    "                batch = 'train'\n",
    "            if 'val' in gfile:\n",
    "                batch = 'val'\n",
    "            if 'test' in gfile:\n",
    "                batch = 'test'\n",
    "            nSteps.append(len(jdict[episode])-1)\n",
    "            start = np.array(jdict[episode]['step_0']['drone_position'], dtype=float)\n",
    "            goal = np.array(jdict[episode]['step_0']['goal_position'], dtype=float)\n",
    "            last_distance = np.linalg.norm(goal-start)\n",
    "            rs = []\n",
    "            norm_verts = [0, 0, 0, 0]\n",
    "            for step in jdict[episode]:\n",
    "                if step == 'step_0':\n",
    "                    continue\n",
    "                state = jdict[episode][step]\n",
    "                actions = state['rl_output'][:2]\n",
    "                observation_name = state['observation_name']\n",
    "                observation = observations[observation_name]\n",
    "                drone = np.array(state['drone_position'], dtype=float)\n",
    "                this_distance = np.linalg.norm(goal-drone)\n",
    "                delta_distance = last_distance - this_distance\n",
    "                vert_distance = abs((goal - drone)[2])\n",
    "                norm_vert = np.interp(vert_distance,\n",
    "                     (min_input, max_input),\n",
    "                     (min_output, max_output),\n",
    "                   left=left,\n",
    "                   right=right,\n",
    "                )\n",
    "                # rotate norm_verts\n",
    "                norm_verts[3] = norm_verts[2]\n",
    "                norm_verts[2] = norm_verts[1]\n",
    "                norm_verts[1] = norm_verts[0]\n",
    "                norm_verts[0] = norm_vert\n",
    "                \n",
    "                x_old = list(observation)\n",
    "                x = np.zeros(len(x_old) + 4, dtype=float)\n",
    "                for i in range(4):\n",
    "                    l1 = i*53\n",
    "                    l2 = i*52\n",
    "                    x[l1:l1+53] = x_old[l2+2:l2+52] + [x_old[l2+0], x_old[l2+1], norm_verts[i]]\n",
    "                x = list(x)\n",
    "                Xs[batch].append(x)\n",
    "                y_old = list(np.clip(actions, -1, 1)) # forward, rotate\n",
    "                y = [y_old[0], 0, y_old[1]]#, 1, 1, 1] # forward, vertical, rotate, slim, res1, res2\n",
    "                Ys[batch].append(y)\n",
    "                XYs[batch].append(x + y)\n",
    "                \n",
    "                if this_distance <= 4:\n",
    "                    r = 100\n",
    "                else:\n",
    "                    r = .1*np.tanh(delta_distance) - 1\n",
    "                rs.append(r)\n",
    "                if this_distance <= 4:\n",
    "                    break\n",
    "                    \n",
    "                last_distance = this_distance\n",
    "                \n",
    "            qs = [100]\n",
    "            gamma = 0.99\n",
    "            for i in range(len(rs)-2,-1,-1):\n",
    "                qs.append(rs[i] + gamma * qs[-1])\n",
    "            qs = qs[::-1]\n",
    "            Qs[batch] = Qs[batch] + qs\n",
    "for batch in Xs:\n",
    "    Xs[batch] = np.array(Xs[batch])\n",
    "for batch in Ys:\n",
    "    Ys[batch] = np.array(Ys[batch])\n",
    "for batch in XYs:\n",
    "    XYs[batch] = np.array(XYs[batch])\n",
    "for batch in Qs:\n",
    "    Qs[batch] = np.array(Qs[batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "978f7ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'SECON3_Fuse_Horz/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fd3acbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetActor(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.as_tensor(X.copy(), device = torch.device(\"cpu\")).float()\n",
    "        self.y = torch.as_tensor(y.copy(), device = torch.device(\"cpu\")).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    \n",
    "training_set = DatasetActor(Xs['train'], Ys['train'])\n",
    "validation_set = DatasetActor(Xs['val'], Ys['val'])\n",
    "testing_set = DatasetActor(Xs['test'], Ys['test'])\n",
    "\n",
    "batch_size = 32\n",
    "params = {'batch_size': batch_size,\n",
    "          'shuffle': True,}\n",
    "training_loader = torch.utils.data.DataLoader(training_set, **params)\n",
    "params = {'batch_size': batch_size,\n",
    "          'shuffle': False,}\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, **params)\n",
    "testing_loader = torch.utils.data.DataLoader(testing_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99993a95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7543/3420914935.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnRuns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'run_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_7543/3420914935.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(params, save_model, name)\u001b[0m\n\u001b[1;32m    155\u001b[0m                     \u001b[0mp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'Slim'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "table = []\n",
    "save_model = True\n",
    "if not save_model and os.path.exists(data_dir + 'actor_hyperopt.p'):\n",
    "    file = open(data_dir + 'actor_hyperopt.p', 'rb')\n",
    "    table = pickle.load(file)\n",
    "if save_model and os.path.exists(data_dir + 'models/actor_runs.p'):\n",
    "    file = open(data_dir + 'models/actor_runs.p', 'rb')\n",
    "    table = pickle.load(file)\n",
    "\n",
    "def objective(params, save_model=False, name=None):\n",
    "    sw = Stopwatch()\n",
    "    \n",
    "    #nLayers = int(3)\n",
    "    #nNodes = 2**int(5)\n",
    "    net_arch = [64, 32, 32]\n",
    "    nLayers = len(net_arch)\n",
    "    learning_rate = 10**(int(-1*3))/7 #params['learning_rate']))\n",
    "    weight_decay = 10**(int(-1*6))\n",
    "    eps = 1e-8#10**(int(-1*int(params['eps'])))\n",
    "    patience = 10#int(params['patience'])\n",
    "\n",
    "    activation_fn = nn.ReLU\n",
    "    with_bias = True\n",
    "    input_dim = Xs['train'].shape[1]\n",
    "    output_dim = Ys['train'].shape[1]\n",
    "\n",
    "    modules = []\n",
    "    if nLayers == 0:\n",
    "        modules.append(Slim(input_dim, output_dim, bias=with_bias, slim_in=False, slim_out=False))\n",
    "    else:\n",
    "        modules.append(Slim(input_dim, net_arch[0], bias=with_bias, slim_in=False))\n",
    "        modules.append(activation_fn())\n",
    "        for idx in range(len(net_arch) - 1):\n",
    "            modules.append(Slim(net_arch[idx], net_arch[idx + 1], bias=with_bias))\n",
    "            modules.append(activation_fn())\n",
    "        modules.append(Slim(net_arch[-1], output_dim, bias=with_bias, slim_out=False))\n",
    "    modules.append(nn.Tanh())\n",
    "    \n",
    "    actor = nn.Sequential(*modules)\n",
    "    device = torch.device(\"cpu\")\n",
    "    actor.cpu()\n",
    "    actor.optimizer = torch.optim.Adam(\n",
    "        actor.parameters(),\n",
    "        amsgrad=False,\n",
    "        betas= (0.9, 0.999),\n",
    "        capturable= False,\n",
    "        differentiable= False,\n",
    "        eps= eps,\n",
    "        foreach= None,\n",
    "        fused= False,\n",
    "        lr= learning_rate,\n",
    "        maximize= False,\n",
    "        weight_decay= weight_decay,\n",
    "    )\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    max_epochs = 10_000\n",
    "    nTrain = training_set.X.size()[0]\n",
    "    nVal = validation_set.X.size()[0]\n",
    "    nTest = testing_set.X.size()[0]\n",
    "    train_rmses = []\n",
    "    val_rmses = []\n",
    "    wait = 0\n",
    "    best_val = 999_999\n",
    "    best_weights = copy.deepcopy(actor.state_dict())\n",
    "\n",
    "    test_rmses = []\n",
    "    test_sse = 0\n",
    "    for i, data in enumerate(testing_loader):\n",
    "        x, y = data\n",
    "        p = actor(x)\n",
    "        loss = criterion(p, y)\n",
    "        test_mse = loss.detach().cpu().numpy()\n",
    "        test_sse += test_mse * x.size()[0]\n",
    "    test_rmse = math.sqrt(test_sse / nTest)\n",
    "    test_rmses.append(test_rmse)\n",
    "\n",
    "    train_sse = 0\n",
    "    for i, data in enumerate(training_loader):\n",
    "        x, y = data\n",
    "        p = actor(x)\n",
    "        loss = criterion(p, y)\n",
    "        train_mse = loss.detach().cpu().numpy()\n",
    "        train_sse += train_mse * x.size()[0]\n",
    "    train_rmse = math.sqrt(train_sse / nTrain)\n",
    "    train_rmses.append(train_rmse)\n",
    "\n",
    "    val_sse = 0\n",
    "    for i, data in enumerate(validation_loader):\n",
    "        x, y = data\n",
    "        p = actor(x)\n",
    "        loss = criterion(p, y)\n",
    "        val_mse = loss.detach().cpu().numpy()\n",
    "        val_sse += val_mse * x.size()[0]\n",
    "    val_rmse = math.sqrt(val_sse / nVal)\n",
    "    val_rmses.append(val_rmse)\n",
    "\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "\n",
    "        train_sse = 0\n",
    "        for i, data in enumerate(training_loader):\n",
    "            x, y = data\n",
    "            p = actor(x)\n",
    "            actor.optimizer.zero_grad()\n",
    "            loss = criterion(p, y)\n",
    "            loss.backward(retain_graph=True)\n",
    "            # inplace distillation \n",
    "            sample_slim = np.random.uniform(low=0.125, high=1.0, size=2)\n",
    "            slim_samples = [0.125] + list(sample_slim)\n",
    "            for slim in slim_samples:\n",
    "                for module in actor.modules():\n",
    "                    if 'Slim' in str(type(module)):\n",
    "                        module.slim = slim\n",
    "                for j in range(3):\n",
    "                    if j == 0:\n",
    "                        level = 1\n",
    "                    else:\n",
    "                        level = np.random.randint(low=1, high=3)\n",
    "                    x_res = torch.clone(x)\n",
    "                    for i in range(4):\n",
    "                        left = i*53\n",
    "                        if level == 0:\n",
    "                            for j in range(25):\n",
    "                                x_res[:, left+j] = 0\n",
    "                        if level == 1:\n",
    "                            for j in range(25):\n",
    "                                if j == 12:\n",
    "                                    continue\n",
    "                                x_res[:, left+j] = 0\n",
    "                        if level == 2:\n",
    "                            for j in range(25):\n",
    "                                if j in [0, 1, 2, 3, 4, 5, 9, 10, 12, 14, 15, 19, 20, 21, 22, 23, 24]:\n",
    "                                    continue\n",
    "                                x_res[:, left+j] = 0\n",
    "                    if j == 0:\n",
    "                        level = 0\n",
    "                    else:\n",
    "                        level = np.random.randint(low=0, high=3)\n",
    "                    for i in range(4):\n",
    "                        left = i*53 + 25\n",
    "                        if level == 0:\n",
    "                            for j in range(25):\n",
    "                                x_res[:, left+j] = 0\n",
    "                        if level == 1:\n",
    "                            for j in range(25):\n",
    "                                if j == 12:\n",
    "                                    continue\n",
    "                                x_res[:, left+j] = 0\n",
    "                        if level == 2:\n",
    "                            for j in range(25):\n",
    "                                if j in [0, 1, 2, 3, 4, 5, 9, 10, 12, 14, 15, 19, 20, 21, 22, 23, 24]:\n",
    "                                    continue\n",
    "                                x_res[:, left+j] = 0\n",
    "                    p2 = actor(x_res)\n",
    "                    loss = criterion(p2, p)\n",
    "                    loss.backward(retain_graph=True)\n",
    "            for module in actor.modules():\n",
    "                if 'Slim' in str(type(module)):\n",
    "                    module.slim = 1\n",
    "            actor.optimizer.step()\n",
    "            train_mse = loss.detach().cpu().numpy()\n",
    "            train_sse += train_mse * x.size()[0]\n",
    "        train_rmse = math.sqrt(train_sse / nTrain)\n",
    "        train_rmses.append(train_rmse)\n",
    "\n",
    "        val_sse = 0\n",
    "        for i, data in enumerate(validation_loader):\n",
    "            x, y = data\n",
    "            p = actor(x)\n",
    "            loss = criterion(p, y)\n",
    "            val_mse = loss.detach().cpu().numpy()\n",
    "            val_sse += val_mse * x.size()[0]\n",
    "        val_rmse = math.sqrt(val_sse / nVal)\n",
    "        val_rmses.append(val_rmse)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        plt.plot(train_rmses, label='Train')\n",
    "        plt.plot(val_rmses, label='Val')\n",
    "        plt.title(name + ' ' + str(params))\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('RMSE - Action Space')\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.show()\n",
    "\n",
    "        if val_rmse < best_val:\n",
    "            best_val = val_rmse\n",
    "            best_weights = copy.deepcopy(actor.state_dict())\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "        if wait > patience:\n",
    "            break\n",
    "\n",
    "    actor.load_state_dict(best_weights)\n",
    "\n",
    "    test_sse = 0\n",
    "    for i, data in enumerate(testing_loader):\n",
    "        x, y = data\n",
    "        p = actor(x)\n",
    "        loss = criterion(p, y)\n",
    "        test_mse = loss.detach().cpu().numpy()\n",
    "        test_sse += test_mse * x.size()[0]\n",
    "    test_rmse = math.sqrt(test_sse / nTest)\n",
    "    test_rmses.append(test_rmse)\n",
    "                       \n",
    "    dt = sw.stop()\n",
    "                       \n",
    "    results = params.copy()\n",
    "    results['time'] = dt\n",
    "    results['train'] = train_rmses\n",
    "    results['val'] = val_rmses\n",
    "    results['test'] = test_rmses\n",
    "    table.append(results)\n",
    "    if save_model:\n",
    "        file = open(data_dir + 'models/actor_runs.p', 'wb')\n",
    "        pickle.dump(table, file)\n",
    "        path = data_dir + 'models/actor_' + name + '.pt'\n",
    "        torch.save(actor.state_dict(), path)\n",
    "    else:\n",
    "        file = open(data_dir + 'actor_hyperopt.p', 'wb')\n",
    "        pickle.dump(table, file)           \n",
    "    return test_rmses[1]\n",
    "                       \n",
    "\n",
    "'''                       \n",
    "# define grid space of hyperparameters to explore\n",
    "space = {\n",
    "    'nLayers':hp.quniform('nLayers', 0, 18, 1),\n",
    "    'nNodes':hp.quniform('nNodes', 0, 14, 1),\n",
    "    #'learning_rate':hp.quniform('learning_rate', 2, 10, 1),\n",
    "    'weight_decay':hp.quniform('weight_decay', 0, 20, 1),\n",
    "    #'eps':hp.quniform('eps', -2, 4, 1),\n",
    "    #'patience':hp.quniform('patience', 10, 40, 1),\n",
    "}\n",
    "# run Hyperopt - minimizing the objective function, with the given grid space, using TPE method, and 16 max iterations\n",
    "best = fmin(objective, space, algo=tpe.suggest, max_evals=100)\n",
    "'''\n",
    "'''\n",
    "for nLayers in range(0, 11):\n",
    "    for nNodes in range(0, 11):\n",
    "        for weight_decay in range(0, 11):\n",
    "            objective({\n",
    "                'nLayers':nLayers,http://localhost:8888/notebooks/local/pretrain/fuse_horz.ipynb#\n",
    "                'nNodes':nNodes,\n",
    "                'weight_decay':weight_decay,\n",
    "            })\n",
    "'''\n",
    "nRuns = 100\n",
    "for run in range(nRuns):\n",
    "    name = 'run_' + str(run)\n",
    "    objective({}, save_model=True, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f53d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetCritic(torch.utils.data.Dataset):\n",
    "    def __init__(self, Xy, q):\n",
    "        self.Xy = torch.as_tensor(Xy.copy(), device = torch.device(\"cuda\")).float()\n",
    "        self.q = torch.as_tensor(q.copy(), device = torch.device(\"cuda\")).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.q)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.Xy[index], self.q[index]\n",
    "    \n",
    "training_set = DatasetCritic(XYs['train'], Qs['train'])\n",
    "validation_set = DatasetCritic(XYs['val'], Qs['val'])\n",
    "testing_set = DatasetCritic(XYs['test'], Qs['test'])\n",
    "\n",
    "batch_size = 32\n",
    "params = {'batch_size': batch_size,\n",
    "          'shuffle': True,}\n",
    "training_loader = torch.utils.data.DataLoader(training_set, **params)\n",
    "params = {'batch_size': batch_size,\n",
    "          'shuffle': False,}\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, **params)\n",
    "testing_loader = torch.utils.data.DataLoader(testing_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e5c862",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = []\n",
    "save_model = True\n",
    "if not save_model and os.path.exists(data_dir + 'critic_hyperopt.p'):\n",
    "    file = open(data_dir + 'critic_hyperopt.p', 'rb')\n",
    "    table = pickle.load(file)\n",
    "if save_model and os.path.exists(data_dir + 'models/critic_runs.p'):\n",
    "    file = open(data_dir + 'models/critic_runs.p', 'rb')\n",
    "    table = pickle.load(file)\n",
    "\n",
    "def objective(params, save_model=False, name=None):\n",
    "    sw = Stopwatch()\n",
    "    \n",
    "    #nLayers = int(3)\n",
    "    #nNodes = 2**int(5)\n",
    "    net_arch = [64, 32, 32]\n",
    "    nLayers = len(net_arch)\n",
    "    learning_rate = 10**(int(-1*3))/4 #params['learning_rate']))\n",
    "    weight_decay = 10**(int(-1*6))\n",
    "    eps = 1e-8#10**(int(-1*int(params['eps'])))\n",
    "    patience = 10#int(params['patience'])\n",
    "\n",
    "    activation_fn = nn.ReLU\n",
    "    with_bias = True\n",
    "    input_dim = Xs['train'].shape[1] + Ys['train'].shape[1]\n",
    "    output_dim = 1\n",
    "\n",
    "    modules = []\n",
    "    if nLayers == 0:\n",
    "        modules.append(Slim(input_dim, output_dim, bias=with_bias, slim_in=False, slim_out=False))\n",
    "    else:\n",
    "        modules.append(Slim(input_dim, net_arch[0], bias=with_bias, slim_in=False))\n",
    "        modules.append(activation_fn())\n",
    "        for idx in range(len(net_arch) - 1):\n",
    "            modules.append(Slim(net_arch[idx], net_arch[idx + 1], bias=with_bias))\n",
    "            modules.append(activation_fn())\n",
    "        modules.append(Slim(net_arch[-1], output_dim, bias=with_bias, slim_out=False))\n",
    "    \n",
    "    critic = nn.Sequential(*modules)\n",
    "    device = torch.device(\"cuda\")\n",
    "    critic.cuda()\n",
    "    critic.optimizer = torch.optim.Adam(\n",
    "        critic.parameters(),\n",
    "        amsgrad=False,\n",
    "        betas= (0.9, 0.999),\n",
    "        capturable= False,\n",
    "        differentiable= False,\n",
    "        eps= eps,\n",
    "        foreach= None,\n",
    "        fused= False,\n",
    "        lr= learning_rate,\n",
    "        maximize= False,\n",
    "        weight_decay= weight_decay,\n",
    "    )\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    max_epochs = 1000\n",
    "    nTrain = training_set.Xy.size()[0]\n",
    "    nVal = validation_set.Xy.size()[0]\n",
    "    nTest = testing_set.Xy.size()[0]\n",
    "    train_rmses = []\n",
    "    val_rmses = []\n",
    "    wait = 0\n",
    "    best_val = 999_999\n",
    "    best_weights = copy.deepcopy(critic.state_dict())\n",
    "\n",
    "    test_rmses = []\n",
    "    test_sse = 0\n",
    "    for i, data in enumerate(testing_loader):\n",
    "        xy, q = data\n",
    "        p = critic(xy)\n",
    "        loss = criterion(p, q)\n",
    "        test_mse = loss.detach().cpu().numpy()\n",
    "        test_sse += test_mse * xy.size()[0]\n",
    "    test_rmse = math.sqrt(test_sse / nTest)\n",
    "    test_rmses.append(test_rmse)\n",
    "\n",
    "    train_sse = 0\n",
    "    for i, data in enumerate(training_loader):\n",
    "        xy, q = data\n",
    "        p = critic(xy)\n",
    "        loss = criterion(p, q)\n",
    "        train_mse = loss.detach().cpu().numpy()\n",
    "        train_sse += train_mse * xy.size()[0]\n",
    "    train_rmse = math.sqrt(train_sse / nTrain)\n",
    "    train_rmses.append(train_rmse)\n",
    "\n",
    "    val_sse = 0\n",
    "    for i, data in enumerate(validation_loader):\n",
    "        xy, q = data\n",
    "        p = critic(xy)\n",
    "        loss = criterion(p, q)\n",
    "        val_mse = loss.detach().cpu().numpy()\n",
    "        val_sse += val_mse * xy.size()[0]\n",
    "    val_rmse = math.sqrt(val_sse / nVal)\n",
    "    val_rmses.append(val_rmse)\n",
    "\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "\n",
    "        train_sse = 0\n",
    "        for i, data in enumerate(training_loader):\n",
    "            xy, q = data\n",
    "            p = critic(xy)\n",
    "            loss = criterion(p, q)\n",
    "            critic.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            critic.optimizer.step()\n",
    "            train_mse = loss.detach().cpu().numpy()\n",
    "            train_sse += train_mse * xy.size()[0]\n",
    "        train_rmse = math.sqrt(train_sse / nTrain)\n",
    "        train_rmses.append(train_rmse)\n",
    "\n",
    "        val_sse = 0\n",
    "        for i, data in enumerate(validation_loader):\n",
    "            xy, q = data\n",
    "            p = critic(xy)\n",
    "            loss = criterion(p, q)\n",
    "            val_mse = loss.detach().cpu().numpy()\n",
    "            val_sse += val_mse * xy.size()[0]\n",
    "        val_rmse = math.sqrt(val_sse / nVal)\n",
    "        val_rmses.append(val_rmse)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        plt.plot(train_rmses, label='Train')\n",
    "        plt.plot(val_rmses, label='Val')\n",
    "        plt.title(name + ' ' + str(params))\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('RMSE - Q Value')\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.show()\n",
    "\n",
    "        if val_rmse < best_val:\n",
    "            best_val = val_rmse\n",
    "            best_weights = copy.deepcopy(critic.state_dict())\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "        if wait > patience:\n",
    "            break\n",
    "\n",
    "    critic.load_state_dict(best_weights)\n",
    "\n",
    "    test_sse = 0\n",
    "    for i, data in enumerate(testing_loader):\n",
    "        xy, q = data\n",
    "        p = critic(xy)\n",
    "        loss = criterion(p, q)\n",
    "        test_mse = loss.detach().cpu().numpy()\n",
    "        test_sse += test_mse * xy.size()[0]\n",
    "    test_rmse = math.sqrt(test_sse / nTest)\n",
    "    test_rmses.append(test_rmse)\n",
    "                       \n",
    "    dt = sw.stop()\n",
    "                       \n",
    "    results = params.copy()\n",
    "    results['time'] = dt\n",
    "    results['train'] = train_rmses\n",
    "    results['val'] = val_rmses\n",
    "    results['test'] = test_rmses\n",
    "    table.append(results)\n",
    "    if save_model:\n",
    "        file = open(data_dir + 'models/critic_runs.p', 'wb')\n",
    "        pickle.dump(table, file)\n",
    "        path = data_dir + 'models/critic_' + name + '.pt'\n",
    "        torch.save(critic.state_dict(), path)\n",
    "    else:\n",
    "        file = open(data_dir + 'critic_hyperopt.p', 'wb')\n",
    "        pickle.dump(table, file)           \n",
    "    return test_rmses[1]\n",
    "                       \n",
    "\n",
    "'''                       \n",
    "# define grid space of hyperparameters to explore\n",
    "space = {\n",
    "    'nLayers':hp.quniform('nLayers', 0, 18, 1),\n",
    "    'nNodes':hp.quniform('nNodes', 0, 14, 1),\n",
    "    #'learning_rate':hp.quniform('learning_rate', 2, 10, 1),\n",
    "    'weight_decay':hp.quniform('weight_decay', 0, 20, 1),\n",
    "    #'eps':hp.quniform('eps', -2, 4, 1),\n",
    "    #'patience':hp.quniform('patience', 10, 40, 1),\n",
    "}}}}\n",
    "# run Hyperopt - minimizing the objective function, with the given grid space, usdata_dirdata_dirdata_diring TPE method, and 16 max iterations\n",
    "best = fmin(objective, space, algo=tpe.suggest, max_evals=100)\n",
    "'''\n",
    "'''\n",
    "for nLayers in range(0, 11):\n",
    "    for nNodes in range(0, 11):\n",
    "        for weight_decay in range(0, 11):\n",
    "            objective({\n",
    "                'nLayers':nLayers,\n",
    "                'nNodes':nNodes,\n",
    "                'weight_decay':weight_decay,\n",
    "            })\n",
    "'''\n",
    "nRuns = 100\n",
    "for run in range(nRuns):\n",
    "    name = 'run_' + str(run)\n",
    "    objective({}, save_model=True, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ee0a936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_arch = [64, 32, 32]\n",
    "nLayers = len(net_arch)\n",
    "learning_rate = 10**(int(-1*3))/4 #params['learning_rate']))\n",
    "weight_decay = 10**(int(-1*6))\n",
    "eps = 1e-8#10**(int(-1*int(params['eps'])))\n",
    "patience = 10#int(params['patience'])\n",
    "\n",
    "activation_fn = nn.ReLU\n",
    "with_bias = True\n",
    "input_dim = Xs['train'].shape[1] + Ys['train'].shape[1]\n",
    "output_dim = 1\n",
    "\n",
    "modules = []\n",
    "if nLayers == 0:\n",
    "    modules.append(Slim(input_dim, output_dim, bias=with_bias, slim_in=False, slim_out=False))\n",
    "else:\n",
    "    modules.append(Slim(input_dim, net_arch[0], bias=with_bias, slim_in=False))\n",
    "    modules.append(activation_fn())\n",
    "    for idx in range(len(net_arch) - 1):\n",
    "        modules.append(Slim(net_arch[idx], net_arch[idx + 1], bias=with_bias))\n",
    "        modules.append(activation_fn())\n",
    "    modules.append(Slim(net_arch[-1], output_dim, bias=with_bias, slim_out=False))\n",
    "\n",
    "critic2 = nn.Sequential(*modules)\n",
    "device = torch.device(\"cuda\")\n",
    "critic2.cuda()\n",
    "critic2.optimizer = torch.optim.Adam(\n",
    "    critic.parameters(),\n",
    "    amsgrad=False,\n",
    "    betas= (0.9, 0.999),\n",
    "    capturable= False,\n",
    "    differentiable= False,\n",
    "    eps= eps,\n",
    "    foreach= None,\n",
    "    fused= False,\n",
    "    lr= learning_rate,\n",
    "    maximize= False,\n",
    "    weight_decay= weight_decay,\n",
    ")\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6889e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(testing_loader):\n",
    "    xy, q = data\n",
    "    p = critic(xy)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6a71e163",
   "metadata": {},
   "outputs": [],
   "source": [
    "nCritics = 2\n",
    "critics = [critic, critic2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "128280b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes an estimate on q-values given array of input data and actions\n",
    "def crit(ini, return_min=True):\n",
    "    # take min of all q-values\n",
    "    q_vals = torch.zeros((len(ini), nCritics))\n",
    "    for c in range(nCritics):\n",
    "        q_vals[:, c] = critics[c](ini).flatten()\n",
    "    if return_min:\n",
    "        return torch.min(q_vals, dim=1, keepdim=True)[0]\n",
    "    return q_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ff9df355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crit(xy).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87eb31bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_vals = torch.zeros((len(xy), nCritics))\n",
    "q_vals.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "beffc0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = critics[0](xy)\n",
    "p.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2cf85ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_vals[:,0] = p.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4aa82152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1607],\n",
       "        [0.1442],\n",
       "        [0.1430],\n",
       "        [0.1422],\n",
       "        [0.1424],\n",
       "        [0.1549],\n",
       "        [0.1521],\n",
       "        [0.1346],\n",
       "        [0.1457],\n",
       "        [0.1426],\n",
       "        [0.1416],\n",
       "        [0.1410],\n",
       "        [0.1410],\n",
       "        [0.1414],\n",
       "        [0.1411],\n",
       "        [0.1410],\n",
       "        [0.1408],\n",
       "        [0.1408],\n",
       "        [0.1636],\n",
       "        [0.1409],\n",
       "        [0.1422],\n",
       "        [0.1468],\n",
       "        [0.1482],\n",
       "        [0.1473],\n",
       "        [0.1520],\n",
       "        [0.1451],\n",
       "        [0.1631],\n",
       "        [0.1446],\n",
       "        [0.1394],\n",
       "        [0.1425],\n",
       "        [0.1372],\n",
       "        [0.1418]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c255ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(testing_loader):\n",
    "    x, y = data\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "39648a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2762, 1.0000, 1.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 1.0000, 1.0000,  ..., 1.0000, 0.0000, 0.2500],\n",
       "        [1.0000, 1.0000, 1.0000,  ..., 0.8000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [1.0000, 1.0000, 1.0000,  ..., 0.8000, 0.0000, 0.0000],\n",
       "        [1.0000, 1.0000, 1.0000,  ..., 0.8000, 0.0000, 0.0000],\n",
       "        [1.0000, 1.0000, 1.0000,  ..., 0.8000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([x, y], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dc43830b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2762, 1.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 1.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 1.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [1.0000, 1.0000, 1.0000,  ..., 0.6448, 0.9180, 0.0000],\n",
       "        [1.0000, 1.0000, 1.0000,  ..., 0.5783, 0.9048, 0.0000],\n",
       "        [1.0000, 1.0000, 1.0000,  ..., 0.5171, 0.1000, 0.0000]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e473ec34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.0000,  0.0000],\n",
       "        [ 1.0000,  0.0000,  0.2500],\n",
       "        [ 0.8000,  0.0000,  0.0000],\n",
       "        [ 0.8000,  0.0000,  0.0000],\n",
       "        [ 0.8000,  0.0000,  0.2500],\n",
       "        [ 1.0000,  0.0000,  0.2500],\n",
       "        [ 0.8000,  0.0000, -0.2500],\n",
       "        [ 1.0000,  0.0000,  0.0000],\n",
       "        [ 1.0000,  0.0000,  0.0000],\n",
       "        [ 1.0000,  0.0000,  0.0000],\n",
       "        [ 1.0000,  0.0000,  0.2500],\n",
       "        [ 0.8000,  0.0000,  0.0000],\n",
       "        [ 0.8000,  0.0000,  0.0000],\n",
       "        [ 0.8000,  0.0000,  0.0000],\n",
       "        [ 0.8000,  0.0000,  0.0000],\n",
       "        [ 0.8000,  0.0000,  0.0000],\n",
       "        [ 0.8000,  0.0000,  0.0000],\n",
       "        [ 0.8000,  0.0000,  0.2500],\n",
       "        [ 1.0000,  0.0000,  0.0000],\n",
       "        [ 1.0000,  0.0000,  0.0000],\n",
       "        [ 1.0000,  0.0000,  0.0000],\n",
       "        [ 1.0000,  0.0000,  0.0000],\n",
       "        [ 1.0000,  0.0000,  0.0000],\n",
       "        [ 1.0000,  0.0000, -0.2500],\n",
       "        [ 0.8000,  0.0000,  0.0000],\n",
       "        [ 0.8000,  0.0000,  0.2500],\n",
       "        [ 1.0000,  0.0000,  0.0000],\n",
       "        [ 1.0000,  0.0000, -0.2500],\n",
       "        [ 0.8000,  0.0000,  0.0000],\n",
       "        [ 0.8000,  0.0000,  0.0000],\n",
       "        [ 0.8000,  0.0000,  0.0000],\n",
       "        [ 0.8000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "70220ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2762, 1.0000, 1.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 1.0000, 1.0000,  ..., 1.0000, 0.0000, 0.2500],\n",
       "        [1.0000, 1.0000, 1.0000,  ..., 0.8000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [1.0000, 1.0000, 1.0000,  ..., 0.8000, 0.0000, 0.0000],\n",
       "        [1.0000, 1.0000, 1.0000,  ..., 0.8000, 0.0000, 0.0000],\n",
       "        [1.0000, 1.0000, 1.0000,  ..., 0.8000, 0.0000, 0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "85e1d6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.0000,  0.0000],\n",
       "        [ 1.0000,  0.0000,  0.2500],\n",
       "        [ 0.8000,  0.0000,  0.0000],\n",
       "        [ 0.8000,  0.0000,  0.0000],\n",
       "        [ 0.8000,  0.0000,  0.2500],\n",
       "        [ 1.0000,  0.0000,  0.2500],\n",
       "        [ 0.8000,  0.0000, -0.2500],\n",
       "        [ 1.0000,  0.0000,  0.0000],\n",
       "        [ 1.0000,  0.0000,  0.0000],\n",
       "        [ 1.0000,  0.0000,  0.0000],\n",
       "        [ 1.0000,  0.0000,  0.2500],\n",
       "        [ 0.8000,  0.0000,  0.0000],\n",
       "        [ 0.8000,  0.0000,  0.0000],\n",
       "        [ 0.8000,  0.0000,  0.0000],\n",
       "        [ 0.8000,  0.0000,  0.0000],\n",
       "        [ 0.8000,  0.0000,  0.0000],\n",
       "        [ 0.8000,  0.0000,  0.0000],\n",
       "        [ 0.8000,  0.0000,  0.2500],\n",
       "        [ 1.0000,  0.0000,  0.0000],\n",
       "        [ 1.0000,  0.0000,  0.0000],\n",
       "        [ 1.0000,  0.0000,  0.0000],\n",
       "        [ 1.0000,  0.0000,  0.0000],\n",
       "        [ 1.0000,  0.0000,  0.0000],\n",
       "        [ 1.0000,  0.0000, -0.2500],\n",
       "        [ 0.8000,  0.0000,  0.0000],\n",
       "        [ 0.8000,  0.0000,  0.2500],\n",
       "        [ 1.0000,  0.0000,  0.0000],\n",
       "        [ 1.0000,  0.0000, -0.2500],\n",
       "        [ 0.8000,  0.0000,  0.0000],\n",
       "        [ 0.8000,  0.0000,  0.0000],\n",
       "        [ 0.8000,  0.0000,  0.0000],\n",
       "        [ 0.8000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "672399bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00,  8.8612e-02, -4.0081e-01],\n",
       "        [ 8.3839e-01,  2.1158e-01,  1.5523e-01],\n",
       "        [ 6.9364e-01, -3.9884e-02,  6.4996e-02],\n",
       "        [ 1.0000e+00,  1.4441e-01,  1.8257e-01],\n",
       "        [ 5.2490e-01,  1.3333e-02,  3.5151e-01],\n",
       "        [ 1.0000e+00,  1.0142e-02, -9.8470e-02],\n",
       "        [ 1.0000e+00, -1.0109e-01, -3.7255e-01],\n",
       "        [ 1.0000e+00,  1.3926e-02,  4.3813e-01],\n",
       "        [ 1.0000e+00,  1.2609e-01,  1.1550e-02],\n",
       "        [ 1.0000e+00,  1.1701e-01, -1.8285e-01],\n",
       "        [ 9.0324e-01,  1.2871e-01,  6.0057e-01],\n",
       "        [ 1.0000e+00, -1.5612e-01, -2.6534e-01],\n",
       "        [ 7.0706e-01, -5.6040e-02, -3.6850e-03],\n",
       "        [ 8.6268e-01,  1.1504e-01, -2.4281e-01],\n",
       "        [ 6.3533e-01,  3.7938e-01, -4.5190e-01],\n",
       "        [ 8.7083e-01, -1.1214e-01,  6.2100e-02],\n",
       "        [ 6.5662e-01, -1.4306e-01, -3.3514e-01],\n",
       "        [ 7.5888e-01,  1.3282e-01, -9.6560e-02],\n",
       "        [ 9.6880e-01, -7.5884e-02,  1.8722e-01],\n",
       "        [ 1.0000e+00, -6.5917e-02,  1.9712e-02],\n",
       "        [ 1.0000e+00, -1.6296e-01, -4.1484e-03],\n",
       "        [ 6.4116e-01,  2.1843e-02,  3.3330e-01],\n",
       "        [ 1.0000e+00, -2.3923e-01, -2.9588e-01],\n",
       "        [ 1.0000e+00, -6.8109e-02, -2.3270e-01],\n",
       "        [ 6.8488e-01,  2.4891e-01,  1.5321e-01],\n",
       "        [ 6.6256e-01,  1.4379e-01,  4.1501e-01],\n",
       "        [ 9.4594e-01,  9.8117e-02, -3.1305e-01],\n",
       "        [ 9.8911e-01,  1.1453e-03, -2.6365e-01],\n",
       "        [ 7.4722e-01, -3.9833e-01,  4.7917e-02],\n",
       "        [ 1.0000e+00,  2.0558e-01,  2.3059e-02],\n",
       "        [ 6.6517e-01, -1.0966e-01,  7.9711e-04],\n",
       "        [ 4.5572e-01,  8.8947e-02, -1.3653e-01]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy = y + torch.normal(0, 0.2, size=y.size())\n",
    "torch.clamp(noisy, min=-1, max=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
