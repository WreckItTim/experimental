{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e70c0da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from stable_baselines3 import TD3 as sb3TD3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from hyperopt import fmin, tpe, hp\n",
    "import pickle\n",
    "from torch import Tensor\n",
    "# simple stopwatch to time whatevs, in (float) seconds\n",
    "# keeps track of laps along with final time\n",
    "class Stopwatch:\n",
    "    def __init__(self):\n",
    "            self.start_time = time()\n",
    "            self.last_time = self.start_time\n",
    "            self.laps = []\n",
    "    def lap(self):\n",
    "        this_time = time()\n",
    "        delta_time = this_time - self.last_time\n",
    "        self.laps.append(delta_time)\n",
    "        self.last_time = this_time\n",
    "        return delta_time\n",
    "    def stop(self):\n",
    "        self.stop_time = time()\n",
    "        self.delta_time = self.stop_time - self.start_time\n",
    "        return self.delta_time\n",
    "class Slim(nn.Linear):\n",
    "    def __init__(self, max_in_features: int, max_out_features: int, bias: bool = True,\n",
    "                 device=None, dtype=None,\n",
    "                slim_in=True, slim_out=True) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__(max_in_features, max_out_features, bias, device, dtype)\n",
    "        self.max_in_features = max_in_features\n",
    "        self.max_out_features = max_out_features\n",
    "        self.slim_in = slim_in\n",
    "        self.slim_out = slim_out\n",
    "        self.slim = 1\n",
    "        \n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        if self.slim_in:\n",
    "            self.in_features = int(self.slim * self.max_in_features)\n",
    "        if self.slim_out:\n",
    "            self.out_features = int(self.slim * self.max_out_features)\n",
    "        weight = self.weight[:self.out_features, :self.in_features]\n",
    "        if self.bias is not None:\n",
    "            bias = self.bias[:self.out_features]\n",
    "        else:\n",
    "            bias = self.bias\n",
    "        y = F.linear(input, weight, bias)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aabcb569",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data_beta/' # horizontal, 25x25 forward and belly depths\n",
    "observations = {}\n",
    "files = os.listdir(data_dir)\n",
    "for fname in files:\n",
    "    fpath = data_dir + fname\n",
    "    if 'observations' in fname:\n",
    "        observation_set = np.load(fpath, allow_pickle=True)\n",
    "        observations.update(observation_set)\n",
    "Xs = {\n",
    "    'train':[],\n",
    "    'val':[],\n",
    "    'test':[],\n",
    "}\n",
    "Ys = {\n",
    "    'train':[],\n",
    "    'val':[],\n",
    "    'test':[],\n",
    "}\n",
    "XYs = {\n",
    "    'train':[],\n",
    "    'val':[],\n",
    "    'test':[],\n",
    "}\n",
    "Qs = {\n",
    "    'train':[],\n",
    "    'val':[],\n",
    "    'test':[],\n",
    "}\n",
    "\n",
    "# distance normalization parameters\n",
    "min_input = 125/1000 # min depth (below this is erroneous)\n",
    "max_input = 125 # max depth\n",
    "min_output = 0.1 # reserve 0 for no-data\n",
    "max_output = 1 \n",
    "left = 0 # set all values below range to this\n",
    "right = None\n",
    "\n",
    "nSteps = []\n",
    "for fname in files:\n",
    "    fpath = data_dir + fname\n",
    "    if 'states' in fname:\n",
    "        jdict = json.load(open(fpath, 'r'))\n",
    "        for episode in jdict:\n",
    "            gfile = jdict[episode]['step_0']['fname']\n",
    "            if 'part2' in gfile or 'part3' in gfile or 'vertical' in gfile:\n",
    "                continue\n",
    "            if 'train' in gfile:\n",
    "                batch = 'train'\n",
    "            if 'val' in gfile:\n",
    "                batch = 'val'\n",
    "            if 'test' in gfile:\n",
    "                batch = 'test'\n",
    "            nSteps.append(len(jdict[episode])-1)\n",
    "            start = np.array(jdict[episode]['step_0']['drone_position'], dtype=float)\n",
    "            goal = np.array(jdict[episode]['step_0']['goal_position'], dtype=float)\n",
    "            last_distance = np.linalg.norm(goal-start)\n",
    "            rs = []\n",
    "            norm_verts = [0, 0, 0, 0]\n",
    "            for step in jdict[episode]:\n",
    "                if step == 'step_0':\n",
    "                    continue\n",
    "                state = jdict[episode][step]\n",
    "                actions = state['rl_output'][:2]\n",
    "                observation_name = state['observation_name']\n",
    "                observation = observations[observation_name]\n",
    "                drone = np.array(state['drone_position'], dtype=float)\n",
    "                this_distance = np.linalg.norm(goal-drone)\n",
    "                delta_distance = last_distance - this_distance\n",
    "                vert_distance = abs((goal - drone)[2])\n",
    "                norm_vert = np.interp(vert_distance,\n",
    "                     (min_input, max_input),\n",
    "                     (min_output, max_output),\n",
    "                   left=left,\n",
    "                   right=right,\n",
    "                )\n",
    "                # rotate norm_verts\n",
    "                norm_verts[3] = norm_verts[2]\n",
    "                norm_verts[2] = norm_verts[1]\n",
    "                norm_verts[1] = norm_verts[0]\n",
    "                norm_verts[0] = norm_vert\n",
    "                \n",
    "                x_old = list(observation)\n",
    "                x = np.zeros(len(x_old) + 4, dtype=float)\n",
    "                for i in range(4):\n",
    "                    l1 = i*53\n",
    "                    l2 = i*52\n",
    "                    x[l1:l1+53] = x_old[l2+2:l2+52] + [x_old[l2+0], x_old[l2+1], norm_verts[i]]\n",
    "                x = list(x)\n",
    "                Xs[batch].append(x)\n",
    "                y_old = list(np.clip(actions, -1, 1)) # forward, rotate\n",
    "                y = [y_old[0], 0, y_old[1]]#, 1, 1, 1] # forward, vertical, rotate, slim, res1, res2\n",
    "                Ys[batch].append(y)\n",
    "                XYs[batch].append(x + y)\n",
    "                \n",
    "                if this_distance <= 4:\n",
    "                    r = 100\n",
    "                else:\n",
    "                    r = .1*np.tanh(delta_distance) - 1\n",
    "                rs.append(r)\n",
    "                if this_distance <= 4:\n",
    "                    break\n",
    "                    \n",
    "                last_distance = this_distance\n",
    "                \n",
    "            qs = [100]\n",
    "            gamma = 0.99\n",
    "            for i in range(len(rs)-2,-1,-1):\n",
    "                qs.append(rs[i] + gamma * qs[-1])\n",
    "            qs = qs[::-1]\n",
    "            Qs[batch] = Qs[batch] + qs\n",
    "for batch in Xs:\n",
    "    Xs[batch] = np.array(Xs[batch])\n",
    "for batch in Ys:\n",
    "    Ys[batch] = np.array(Ys[batch])\n",
    "for batch in XYs:\n",
    "    XYs[batch] = np.array(XYs[batch])\n",
    "for batch in Qs:\n",
    "    Qs[batch] = np.array(Qs[batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "978f7ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'SECON3_Res_Horz/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd3acbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetActor(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.as_tensor(X.copy(), device = torch.device(\"cpu\")).float()\n",
    "        self.y = torch.as_tensor(y.copy(), device = torch.device(\"cpu\")).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    \n",
    "training_set = DatasetActor(Xs['train'], Ys['train'])\n",
    "validation_set = DatasetActor(Xs['val'], Ys['val'])\n",
    "testing_set = DatasetActor(Xs['test'], Ys['test'])\n",
    "\n",
    "batch_size = 32\n",
    "params = {'batch_size': batch_size,\n",
    "          'shuffle': True,}\n",
    "training_loader = torch.utils.data.DataLoader(training_set, **params)\n",
    "params = {'batch_size': batch_size,\n",
    "          'shuffle': False,}\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, **params)\n",
    "testing_loader = torch.utils.data.DataLoader(testing_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99993a95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_46173/1434293273.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnRuns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'run_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m     \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_46173/1434293273.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(params, save_model, name)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m             \u001b[0mtrain_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mtrain_sse\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_mse\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             adam(params_with_grad,\n\u001b[0m\u001b[1;32m    235\u001b[0m                  \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                  \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    301\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "table = []\n",
    "save_model = True\n",
    "if not save_model and os.path.exists(data_dir + 'actor_hyperopt.p'):\n",
    "    file = open(data_dir + 'actor_hyperopt.p', 'rb')\n",
    "    table = pickle.load(file)\n",
    "if save_model and os.path.exists(data_dir + 'models/actor_runs.p'):\n",
    "    file = open(data_dir + 'models/actor_runs.p', 'rb')\n",
    "    table = pickle.load(file)\n",
    "\n",
    "def objective(params, save_model=False, name=None):\n",
    "    sw = Stopwatch()\n",
    "    \n",
    "    #nLayers = int(3)\n",
    "    #nNodes = 2**int(5)\n",
    "    net_arch = [64, 32, 32]\n",
    "    nLayers = len(net_arch)\n",
    "    learning_rate = 10**(int(-1*3))/4 #params['learning_rate']))\n",
    "    weight_decay = 10**(int(-1*6))\n",
    "    eps = 1e-8#10**(int(-1*int(params['eps'])))\n",
    "    patience = 10#int(params['patience'])\n",
    "\n",
    "    activation_fn = nn.ReLU\n",
    "    with_bias = True\n",
    "    input_dim = Xs['train'].shape[1]\n",
    "    output_dim = Ys['train'].shape[1]\n",
    "\n",
    "    modules = []\n",
    "    if nLayers == 0:\n",
    "        modules.append(Slim(input_dim, output_dim, bias=with_bias, slim_in=False, slim_out=False))\n",
    "    else:\n",
    "        modules.append(Slim(input_dim, net_arch[0], bias=with_bias, slim_in=False))\n",
    "        modules.append(activation_fn())\n",
    "        for idx in range(len(net_arch) - 1):\n",
    "            modules.append(Slim(net_arch[idx], net_arch[idx + 1], bias=with_bias))\n",
    "            modules.append(activation_fn())\n",
    "        modules.append(Slim(net_arch[-1], output_dim, bias=with_bias, slim_out=False))\n",
    "    modules.append(nn.Tanh())\n",
    "    \n",
    "    actor = nn.Sequential(*modules)\n",
    "    device = torch.device(\"cpu\")\n",
    "    actor.cpu()\n",
    "    actor.optimizer = torch.optim.Adam(\n",
    "        actor.parameters(),\n",
    "        amsgrad=False,\n",
    "        betas= (0.9, 0.999),\n",
    "        capturable= False,\n",
    "        differentiable= False,\n",
    "        eps= eps,\n",
    "        foreach= None,\n",
    "        fused= False,\n",
    "        lr= learning_rate,\n",
    "        maximize= False,\n",
    "        weight_decay= weight_decay,\n",
    "    )\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    max_epochs = 10_000\n",
    "    nTrain = training_set.X.size()[0]\n",
    "    nVal = validation_set.X.size()[0]\n",
    "    nTest = testing_set.X.size()[0]\n",
    "    train_rmses = []\n",
    "    val_rmses = []\n",
    "    wait = 0\n",
    "    best_val = 999_999\n",
    "    best_weights = copy.deepcopy(actor.state_dict())\n",
    "\n",
    "    test_rmses = []\n",
    "    test_sse = 0\n",
    "    for i, data in enumerate(testing_loader):\n",
    "        x, y = data\n",
    "        p = actor(x)\n",
    "        loss = criterion(p, y)\n",
    "        test_mse = loss.detach().cpu().numpy()\n",
    "        test_sse += test_mse * x.size()[0]\n",
    "    test_rmse = math.sqrt(test_sse / nTest)\n",
    "    test_rmses.append(test_rmse)\n",
    "\n",
    "    train_sse = 0\n",
    "    for i, data in enumerate(training_loader):\n",
    "        x, y = data\n",
    "        p = actor(x)\n",
    "        loss = criterion(p, y)\n",
    "        train_mse = loss.detach().cpu().numpy()\n",
    "        train_sse += train_mse * x.size()[0]\n",
    "    train_rmse = math.sqrt(train_sse / nTrain)\n",
    "    train_rmses.append(train_rmse)\n",
    "\n",
    "    val_sse = 0\n",
    "    for i, data in enumerate(validation_loader):\n",
    "        x, y = data\n",
    "        p = actor(x)\n",
    "        loss = criterion(p, y)\n",
    "        val_mse = loss.detach().cpu().numpy()\n",
    "        val_sse += val_mse * x.size()[0]\n",
    "    val_rmse = math.sqrt(val_sse / nVal)\n",
    "    val_rmses.append(val_rmse)\n",
    "\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "\n",
    "        train_sse = 0\n",
    "        for i, data in enumerate(training_loader):\n",
    "            x, y = data\n",
    "            p = actor(x)\n",
    "            actor.optimizer.zero_grad()\n",
    "            loss = criterion(p, y)\n",
    "            loss.backward(retain_graph=True)\n",
    "            # inplace distillation \n",
    "            for j in range(3):\n",
    "                if j == 0:\n",
    "                    level = 1\n",
    "                else:\n",
    "                    level = np.random.randint(low=1, high=3)\n",
    "                x_res = torch.clone(x)\n",
    "                for i in range(4):\n",
    "                    left = i*53\n",
    "                    if level == 0:\n",
    "                        for j in range(25):\n",
    "                            x_res[:, left+j] = 0\n",
    "                    if level == 1:\n",
    "                        for j in range(25):\n",
    "                            if j == 12:\n",
    "                                continue\n",
    "                            x_res[:, left+j] = 0\n",
    "                    if level == 2:\n",
    "                        for j in range(25):\n",
    "                            if j in [0, 1, 2, 3, 4, 5, 9, 10, 12, 14, 15, 19, 20, 21, 22, 23, 24]:\n",
    "                                continue\n",
    "                            x_res[:, left+j] = 0\n",
    "                if j == 0:\n",
    "                    level = 0\n",
    "                else:\n",
    "                    level = np.random.randint(low=0, high=3)\n",
    "                for i in range(4):\n",
    "                    left = i*53 + 25\n",
    "                    if level == 0:\n",
    "                        for j in range(25):\n",
    "                            x_res[:, left+j] = 0\n",
    "                    if level == 1:\n",
    "                        for j in range(25):\n",
    "                            if j == 12:\n",
    "                                continue\n",
    "                            x_res[:, left+j] = 0\n",
    "                    if level == 2:\n",
    "                        for j in range(25):\n",
    "                            if j in [0, 1, 2, 3, 4, 5, 9, 10, 12, 14, 15, 19, 20, 21, 22, 23, 24]:\n",
    "                                continue\n",
    "                            x_res[:, left+j] = 0\n",
    "                p2 = actor(x_res)\n",
    "                loss = criterion(p2, p)\n",
    "                loss.backward(retain_graph=True)\n",
    "            actor.optimizer.step()\n",
    "            train_mse = loss.detach().cpu().numpy()\n",
    "            train_sse += train_mse * x.size()[0]\n",
    "        train_rmse = math.sqrt(train_sse / nTrain)\n",
    "        train_rmses.append(train_rmse)\n",
    "\n",
    "        val_sse = 0\n",
    "        for i, data in enumerate(validation_loader):\n",
    "            x, y = data\n",
    "            p = actor(x)\n",
    "            loss = criterion(p, y)\n",
    "            val_mse = loss.detach().cpu().numpy()\n",
    "            val_sse += val_mse * x.size()[0]\n",
    "        val_rmse = math.sqrt(val_sse / nVal)\n",
    "        val_rmses.append(val_rmse)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        plt.plot(train_rmses, label='Train')\n",
    "        plt.plot(val_rmses, label='Val')\n",
    "        plt.title(name + ' ' + str(params))\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('RMSE - Action Space')\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.show()\n",
    "\n",
    "        if val_rmse < best_val:\n",
    "            best_val = val_rmse\n",
    "            best_weights = copy.deepcopy(actor.state_dict())\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "        if wait > patience:\n",
    "            break\n",
    "\n",
    "    actor.load_state_dict(best_weights)\n",
    "\n",
    "    test_sse = 0\n",
    "    for i, data in enumerate(testing_loader):\n",
    "        x, y = data\n",
    "        p = actor(x)\n",
    "        loss = criterion(p, y)\n",
    "        test_mse = loss.detach().cpu().numpy()\n",
    "        test_sse += test_mse * x.size()[0]\n",
    "    test_rmse = math.sqrt(test_sse / nTest)\n",
    "    test_rmses.append(test_rmse)\n",
    "                       \n",
    "    dt = sw.stop()\n",
    "                       \n",
    "    results = params.copy()\n",
    "    results['time'] = dt\n",
    "    results['train'] = train_rmses\n",
    "    results['val'] = val_rmses\n",
    "    results['test'] = test_rmses\n",
    "    table.append(results)\n",
    "    if save_model:\n",
    "        file = open(data_dir + 'models/actor_runs.p', 'wb')\n",
    "        pickle.dump(table, file)\n",
    "        path = data_dir + 'models/actor_' + name + '.pt'\n",
    "        torch.save(actor.state_dict(), path)\n",
    "    else:\n",
    "        file = open(data_dir + 'actor_hyperopt.p', 'wb')\n",
    "        pickle.dump(table, file)           \n",
    "    return test_rmses[1]\n",
    "                       \n",
    "\n",
    "'''                       \n",
    "# define grid space of hyperparameters to explore\n",
    "space = {\n",
    "    'nLayers':hp.quniform('nLayers', 0, 18, 1),\n",
    "    'nNodes':hp.quniform('nNodes', 0, 14, 1),\n",
    "    #'learning_rate':hp.quniform('learning_rate', 2, 10, 1),\n",
    "    'weight_decay':hp.quniform('weight_decay', 0, 20, 1),\n",
    "    #'eps':hp.quniform('eps', -2, 4, 1),\n",
    "    #'patience':hp.quniform('patience', 10, 40, 1),\n",
    "}\n",
    "# run Hyperopt - minimizing the objective function, with the given grid space, using TPE method, and 16 max iterations\n",
    "best = fmin(objective, space, algo=tpe.suggest, max_evals=100)\n",
    "'''\n",
    "'''\n",
    "for nLayers in range(0, 11):\n",
    "    for nNodes in range(0, 11):\n",
    "        for weight_decay in range(0, 11):\n",
    "            objective({\n",
    "                'nLayers':nLayers,\n",
    "                'nNodes':nNodes,\n",
    "                'weight_decay':weight_decay,\n",
    "            })\n",
    "'''\n",
    "nRuns = 100\n",
    "for run in range(12, nRuns):\n",
    "    name = 'run_' + str(run)\n",
    "    objective({}, save_model=True, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f53d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetCritic(torch.utils.data.Dataset):\n",
    "    def __init__(self, Xy, q):\n",
    "        self.Xy = torch.as_tensor(Xy.copy(), device = torch.device(\"cuda\")).float()\n",
    "        self.q = torch.as_tensor(q.copy(), device = torch.device(\"cuda\")).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.q)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.Xy[index], self.q[index]\n",
    "    \n",
    "training_set = DatasetCritic(XYs['train'], Qs['train'])\n",
    "validation_set = DatasetCritic(XYs['val'], Qs['val'])\n",
    "testing_set = DatasetCritic(XYs['test'], Qs['test'])\n",
    "\n",
    "batch_size = 32\n",
    "params = {'batch_size': batch_size,\n",
    "          'shuffle': True,}\n",
    "training_loader = torch.utils.data.DataLoader(training_set, **params)\n",
    "params = {'batch_size': batch_size,\n",
    "          'shuffle': False,}\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, **params)\n",
    "testing_loader = torch.utils.data.DataLoader(testing_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e5c862",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = []\n",
    "save_model = True\n",
    "if not save_model and os.path.exists(data_dir + 'critic_hyperopt.p'):\n",
    "    file = open(data_dir + 'critic_hyperopt.p', 'rb')\n",
    "    table = pickle.load(file)\n",
    "if save_model and os.path.exists(data_dir + 'models/critic_runs.p'):\n",
    "    file = open(data_dir + 'models/critic_runs.p', 'rb')\n",
    "    table = pickle.load(file)\n",
    "\n",
    "def objective(params, save_model=False, name=None):\n",
    "    sw = Stopwatch()\n",
    "    \n",
    "    #nLayers = int(3)\n",
    "    #nNodes = 2**int(5)\n",
    "    net_arch = [64, 32, 32]\n",
    "    nLayers = len(net_arch)\n",
    "    learning_rate = 10**(int(-1*3))/4 #params['learning_rate']))\n",
    "    weight_decay = 10**(int(-1*6))\n",
    "    eps = 1e-8#10**(int(-1*int(params['eps'])))\n",
    "    patience = 10#int(params['patience'])\n",
    "\n",
    "    activation_fn = nn.ReLU\n",
    "    with_bias = True\n",
    "    input_dim = Xs['train'].shape[1] + Ys['train'].shape[1]\n",
    "    output_dim = 1\n",
    "\n",
    "    modules = []\n",
    "    if nLayers == 0:\n",
    "        modules.append(Slim(input_dim, output_dim, bias=with_bias, slim_in=False, slim_out=False))\n",
    "    else:\n",
    "        modules.append(Slim(input_dim, net_arch[0], bias=with_bias, slim_in=False))\n",
    "        modules.append(activation_fn())\n",
    "        for idx in range(len(net_arch) - 1):\n",
    "            modules.append(Slim(net_arch[idx], net_arch[idx + 1], bias=with_bias))\n",
    "            modules.append(activation_fn())\n",
    "        modules.append(Slim(net_arch[-1], output_dim, bias=with_bias, slim_out=False))\n",
    "    \n",
    "    critic = nn.Sequential(*modules)\n",
    "    device = torch.device(\"cuda\")\n",
    "    critic.cuda()\n",
    "    critic.optimizer = torch.optim.Adam(\n",
    "        critic.parameters(),\n",
    "        amsgrad=False,\n",
    "        betas= (0.9, 0.999),\n",
    "        capturable= False,\n",
    "        differentiable= False,\n",
    "        eps= eps,\n",
    "        foreach= None,\n",
    "        fused= False,\n",
    "        lr= learning_rate,\n",
    "        maximize= False,\n",
    "        weight_decay= weight_decay,\n",
    "    )\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    max_epochs = 1000\n",
    "    nTrain = training_set.Xy.size()[0]\n",
    "    nVal = validation_set.Xy.size()[0]\n",
    "    nTest = testing_set.Xy.size()[0]\n",
    "    train_rmses = []\n",
    "    val_rmses = []\n",
    "    wait = 0\n",
    "    best_val = 999_999\n",
    "    best_weights = copy.deepcopy(critic.state_dict())\n",
    "\n",
    "    test_rmses = []\n",
    "    test_sse = 0\n",
    "    for i, data in enumerate(testing_loader):\n",
    "        xy, q = data\n",
    "        p = critic(xy)\n",
    "        loss = criterion(p, q)\n",
    "        test_mse = loss.detach().cpu().numpy()\n",
    "        test_sse += test_mse * xy.size()[0]\n",
    "    test_rmse = math.sqrt(test_sse / nTest)\n",
    "    test_rmses.append(test_rmse)\n",
    "\n",
    "    train_sse = 0\n",
    "    for i, data in enumerate(training_loader):\n",
    "        xy, q = data\n",
    "        p = critic(xy)\n",
    "        loss = criterion(p, q)\n",
    "        train_mse = loss.detach().cpu().numpy()\n",
    "        train_sse += train_mse * xy.size()[0]\n",
    "    train_rmse = math.sqrt(train_sse / nTrain)\n",
    "    train_rmses.append(train_rmse)\n",
    "\n",
    "    val_sse = 0\n",
    "    for i, data in enumerate(validation_loader):\n",
    "        xy, q = data\n",
    "        p = critic(xy)\n",
    "        loss = criterion(p, q)\n",
    "        val_mse = loss.detach().cpu().numpy()\n",
    "        val_sse += val_mse * xy.size()[0]\n",
    "    val_rmse = math.sqrt(val_sse / nVal)\n",
    "    val_rmses.append(val_rmse)\n",
    "\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "\n",
    "        train_sse = 0\n",
    "        for i, data in enumerate(training_loader):\n",
    "            xy, q = data\n",
    "            p = critic(xy)\n",
    "            loss = criterion(p, q)\n",
    "            critic.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            critic.optimizer.step()\n",
    "            train_mse = loss.detach().cpu().numpy()\n",
    "            train_sse += train_mse * xy.size()[0]\n",
    "        train_rmse = math.sqrt(train_sse / nTrain)\n",
    "        train_rmses.append(train_rmse)\n",
    "\n",
    "        val_sse = 0\n",
    "        for i, data in enumerate(validation_loader):\n",
    "            xy, q = data\n",
    "            p = critic(xy)\n",
    "            loss = criterion(p, q)\n",
    "            val_mse = loss.detach().cpu().numpy()\n",
    "            val_sse += val_mse * xy.size()[0]\n",
    "        val_rmse = math.sqrt(val_sse / nVal)\n",
    "        val_rmses.append(val_rmse)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        plt.plot(train_rmses, label='Train')\n",
    "        plt.plot(val_rmses, label='Val')\n",
    "        plt.title(name + ' ' + str(params))\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('RMSE - Q Value')\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.show()\n",
    "\n",
    "        if val_rmse < best_val:\n",
    "            best_val = val_rmse\n",
    "            best_weights = copy.deepcopy(critic.state_dict())\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "        if wait > patience:\n",
    "            break\n",
    "\n",
    "    critic.load_state_dict(best_weights)\n",
    "\n",
    "    test_sse = 0\n",
    "    for i, data in enumerate(testing_loader):\n",
    "        xy, q = data\n",
    "        p = critic(xy)\n",
    "        loss = criterion(p, q)\n",
    "        test_mse = loss.detach().cpu().numpy()\n",
    "        test_sse += test_mse * xy.size()[0]\n",
    "    test_rmse = math.sqrt(test_sse / nTest)\n",
    "    test_rmses.append(test_rmse)\n",
    "                       \n",
    "    dt = sw.stop()\n",
    "                       \n",
    "    results = params.copy()\n",
    "    results['time'] = dt\n",
    "    results['train'] = train_rmses\n",
    "    results['val'] = val_rmses\n",
    "    results['test'] = test_rmses\n",
    "    table.append(results)\n",
    "    if save_model:\n",
    "        file = open(data_dir + 'models/critic_runs.p', 'wb')\n",
    "        pickle.dump(table, file)\n",
    "        path = data_dir + 'models/critic_' + name + '.pt'\n",
    "        torch.save(critic.state_dict(), path)\n",
    "    else:\n",
    "        file = open(data_dir + 'critic_hyperopt.p', 'wb')\n",
    "        pickle.dump(table, file)           \n",
    "    return test_rmses[1]\n",
    "                       \n",
    "\n",
    "'''                       \n",
    "# define grid space of hyperparameters to explore\n",
    "space = {\n",
    "    'nLayers':hp.quniform('nLayers', 0, 18, 1),\n",
    "    'nNodes':hp.quniform('nNodes', 0, 14, 1),\n",
    "    #'learning_rate':hp.quniform('learning_rate', 2, 10, 1),\n",
    "    'weight_decay':hp.quniform('weight_decay', 0, 20, 1),\n",
    "    #'eps':hp.quniform('eps', -2, 4, 1),\n",
    "    #'patience':hp.quniform('patience', 10, 40, 1),\n",
    "}}}}\n",
    "# run Hyperopt - minimizing the objective function, with the given grid space, usdata_dirdata_dirdata_diring TPE method, and 16 max iterations\n",
    "best = fmin(objective, space, algo=tpe.suggest, max_evals=100)\n",
    "'''\n",
    "'''\n",
    "for nLayers in range(0, 11):\n",
    "    for nNodes in range(0, 11):\n",
    "        for weight_decay in range(0, 11):\n",
    "            objective({\n",
    "                'nLayers':nLayers,\n",
    "                'nNodes':nNodes,\n",
    "                'weight_decay':weight_decay,\n",
    "            })\n",
    "'''\n",
    "nRuns = 100\n",
    "for run in range(nRuns):\n",
    "    name = 'run_' + str(run)\n",
    "    objective({}, save_model=True, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0a936f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
